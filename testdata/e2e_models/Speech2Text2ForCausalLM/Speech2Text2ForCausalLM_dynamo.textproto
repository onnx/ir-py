ir_version: 8
producer_name: "pytorch"
producer_version: "2.2.0"
graph {
  node {
    input: "l_input_ids_"
    input: "model.decoder.embed_tokens.weight"
    input: "model.decoder.embed_positions.weights"
    input: "model.decoder.layers.0.self_attn.q_proj.weight"
    input: "model.decoder.layers.0.self_attn.q_proj.bias"
    input: "model.decoder.layers.0.self_attn.k_proj.weight"
    input: "model.decoder.layers.0.self_attn.k_proj.bias"
    input: "model.decoder.layers.0.self_attn.v_proj.weight"
    input: "model.decoder.layers.0.self_attn.v_proj.bias"
    input: "model.decoder.layers.0.self_attn.out_proj.weight"
    input: "model.decoder.layers.0.self_attn.out_proj.bias"
    input: "model.decoder.layers.0.self_attn_layer_norm.weight"
    input: "model.decoder.layers.0.self_attn_layer_norm.bias"
    input: "model.decoder.layers.0.fc1.weight"
    input: "model.decoder.layers.0.fc1.bias"
    input: "model.decoder.layers.0.fc2.weight"
    input: "model.decoder.layers.0.fc2.bias"
    input: "model.decoder.layers.0.final_layer_norm.weight"
    input: "model.decoder.layers.0.final_layer_norm.bias"
    input: "model.decoder.layers.1.self_attn.q_proj.weight"
    input: "model.decoder.layers.1.self_attn.q_proj.bias"
    input: "model.decoder.layers.1.self_attn.k_proj.weight"
    input: "model.decoder.layers.1.self_attn.k_proj.bias"
    input: "model.decoder.layers.1.self_attn.v_proj.weight"
    input: "model.decoder.layers.1.self_attn.v_proj.bias"
    input: "model.decoder.layers.1.self_attn.out_proj.weight"
    input: "model.decoder.layers.1.self_attn.out_proj.bias"
    input: "model.decoder.layers.1.self_attn_layer_norm.weight"
    input: "model.decoder.layers.1.self_attn_layer_norm.bias"
    input: "model.decoder.layers.1.fc1.weight"
    input: "model.decoder.layers.1.fc1.bias"
    input: "model.decoder.layers.1.fc2.weight"
    input: "model.decoder.layers.1.fc2.bias"
    input: "model.decoder.layers.1.final_layer_norm.weight"
    input: "model.decoder.layers.1.final_layer_norm.bias"
    input: "model.decoder.layers.2.self_attn.q_proj.weight"
    input: "model.decoder.layers.2.self_attn.q_proj.bias"
    input: "model.decoder.layers.2.self_attn.k_proj.weight"
    input: "model.decoder.layers.2.self_attn.k_proj.bias"
    input: "model.decoder.layers.2.self_attn.v_proj.weight"
    input: "model.decoder.layers.2.self_attn.v_proj.bias"
    input: "model.decoder.layers.2.self_attn.out_proj.weight"
    input: "model.decoder.layers.2.self_attn.out_proj.bias"
    input: "model.decoder.layers.2.self_attn_layer_norm.weight"
    input: "model.decoder.layers.2.self_attn_layer_norm.bias"
    input: "model.decoder.layers.2.fc1.weight"
    input: "model.decoder.layers.2.fc1.bias"
    input: "model.decoder.layers.2.fc2.weight"
    input: "model.decoder.layers.2.fc2.bias"
    input: "model.decoder.layers.2.final_layer_norm.weight"
    input: "model.decoder.layers.2.final_layer_norm.bias"
    input: "model.decoder.layers.3.self_attn.q_proj.weight"
    input: "model.decoder.layers.3.self_attn.q_proj.bias"
    input: "model.decoder.layers.3.self_attn.k_proj.weight"
    input: "model.decoder.layers.3.self_attn.k_proj.bias"
    input: "model.decoder.layers.3.self_attn.v_proj.weight"
    input: "model.decoder.layers.3.self_attn.v_proj.bias"
    input: "model.decoder.layers.3.self_attn.out_proj.weight"
    input: "model.decoder.layers.3.self_attn.out_proj.bias"
    input: "model.decoder.layers.3.self_attn_layer_norm.weight"
    input: "model.decoder.layers.3.self_attn_layer_norm.bias"
    input: "model.decoder.layers.3.fc1.weight"
    input: "model.decoder.layers.3.fc1.bias"
    input: "model.decoder.layers.3.fc2.weight"
    input: "model.decoder.layers.3.fc2.bias"
    input: "model.decoder.layers.3.final_layer_norm.weight"
    input: "model.decoder.layers.3.final_layer_norm.bias"
    input: "model.decoder.layers.4.self_attn.q_proj.weight"
    input: "model.decoder.layers.4.self_attn.q_proj.bias"
    input: "model.decoder.layers.4.self_attn.k_proj.weight"
    input: "model.decoder.layers.4.self_attn.k_proj.bias"
    input: "model.decoder.layers.4.self_attn.v_proj.weight"
    input: "model.decoder.layers.4.self_attn.v_proj.bias"
    input: "model.decoder.layers.4.self_attn.out_proj.weight"
    input: "model.decoder.layers.4.self_attn.out_proj.bias"
    input: "model.decoder.layers.4.self_attn_layer_norm.weight"
    input: "model.decoder.layers.4.self_attn_layer_norm.bias"
    input: "model.decoder.layers.4.fc1.weight"
    input: "model.decoder.layers.4.fc1.bias"
    input: "model.decoder.layers.4.fc2.weight"
    input: "model.decoder.layers.4.fc2.bias"
    input: "model.decoder.layers.4.final_layer_norm.weight"
    input: "model.decoder.layers.4.final_layer_norm.bias"
    input: "model.decoder.layers.5.self_attn.q_proj.weight"
    input: "model.decoder.layers.5.self_attn.q_proj.bias"
    input: "model.decoder.layers.5.self_attn.k_proj.weight"
    input: "model.decoder.layers.5.self_attn.k_proj.bias"
    input: "model.decoder.layers.5.self_attn.v_proj.weight"
    input: "model.decoder.layers.5.self_attn.v_proj.bias"
    input: "model.decoder.layers.5.self_attn.out_proj.weight"
    input: "model.decoder.layers.5.self_attn.out_proj.bias"
    input: "model.decoder.layers.5.self_attn_layer_norm.weight"
    input: "model.decoder.layers.5.self_attn_layer_norm.bias"
    input: "model.decoder.layers.5.fc1.weight"
    input: "model.decoder.layers.5.fc1.bias"
    input: "model.decoder.layers.5.fc2.weight"
    input: "model.decoder.layers.5.fc2.bias"
    input: "model.decoder.layers.5.final_layer_norm.weight"
    input: "model.decoder.layers.5.final_layer_norm.bias"
    output: "model_decoder_1"
    output: "model_decoder_1_1"
    output: "model_decoder_1_2"
    output: "model_decoder_1_3"
    output: "model_decoder_1_4"
    output: "model_decoder_1_5"
    output: "model_decoder_1_6"
    output: "model_decoder_1_7"
    output: "model_decoder_1_8"
    output: "model_decoder_1_9"
    output: "model_decoder_1_10"
    output: "model_decoder_1_11"
    output: "model_decoder_1_12"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1_7"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_1_12"
    input: "model.decoder.embed_tokens.weight"
    output: "lm_head_1"
    name: "torch_nn_modules_linear_Linear_lm_head_1_8"
    op_type: "torch_nn_modules_linear_Linear_lm_head_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_114"
    name: "Constant_9"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\377\377\377\377\377\377\377\377\020\'\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "lm_head_1"
    input: "_val_114"
    output: "view_138"
    name: "aten_view_10"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_116"
    name: "Constant_11"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 1
        data_type: 7
        raw_data: "\377\377\377\377\377\377\377\377"
      }
      type: TENSOR
    }
  }
  node {
    input: "l_labels_"
    input: "_val_116"
    output: "view_139"
    name: "aten_view_12"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_138"
    output: "_log_softmax"
    name: "aten__log_softmax_13"
    op_type: "aten__log_softmax"
    attribute {
      name: "dim"
      i: 1
      type: INT
    }
    attribute {
      name: "half_to_float"
      i: 0
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_119"
    name: "Constant_14"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\234\377\377\377\377\377\377\377"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_139"
    input: "_val_119"
    output: "ne_1"
    name: "aten_ne_15"
    op_type: "aten_ne"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_121"
    name: "Constant_16"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\000\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_121"
    output: "scalar_tensor"
    name: "aten_scalar_tensor_sym_number_17"
    op_type: "aten_scalar_tensor_sym_number"
    attribute {
      name: "dtype"
      i: 7
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "ne_1"
    input: "view_139"
    input: "scalar_tensor"
    output: "where"
    name: "aten_where_18"
    op_type: "aten_where"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "where"
    output: "unsqueeze_4"
    name: "aten_unsqueeze_19"
    op_type: "aten_unsqueeze"
    attribute {
      name: "dim"
      i: 1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "_log_softmax"
    input: "unsqueeze_4"
    output: "gather"
    name: "aten_gather_20"
    op_type: "aten_gather"
    attribute {
      name: "dim"
      i: 1
      type: INT
    }
    attribute {
      name: "sparse_grad"
      i: 0
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "gather"
    output: "squeeze"
    name: "aten_squeeze_dim_21"
    op_type: "aten_squeeze_dim"
    attribute {
      name: "dim"
      i: 1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "squeeze"
    output: "neg"
    name: "aten_neg_22"
    op_type: "aten_neg"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_128"
    name: "Constant_23"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\234\377\377\377\377\377\377\377"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_139"
    input: "_val_128"
    output: "ne_2"
    name: "aten_ne_24"
    op_type: "aten_ne"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_130"
    name: "Constant_25"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\000\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_130"
    output: "scalar_tensor_1"
    name: "aten_scalar_tensor_sym_number_26"
    op_type: "aten_scalar_tensor_sym_number"
    attribute {
      name: "dtype"
      i: 1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "ne_2"
    input: "neg"
    input: "scalar_tensor_1"
    output: "where_1"
    name: "aten_where_27"
    op_type: "aten_where"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_133"
    name: "Constant_28"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\234\377\377\377\377\377\377\377"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_139"
    input: "_val_133"
    output: "ne_3"
    name: "aten_ne_29"
    op_type: "aten_ne"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "ne_3"
    output: "convert_element_type_default_1"
    name: "prims_convert_element_type_30"
    op_type: "prims_convert_element_type"
    attribute {
      name: "dtype"
      i: 7
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "convert_element_type_default_1"
    output: "sum_1"
    name: "_aten_sum_dim_none_31"
    op_type: "_aten_sum_dim_none"
    attribute {
      name: "keepdim"
      i: 0
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "sum_1"
    output: "convert_element_type_3"
    name: "prims_convert_element_type_32"
    op_type: "prims_convert_element_type"
    attribute {
      name: "dtype"
      i: 1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "where_1"
    output: "sum_2"
    name: "_aten_sum_dim_none_33"
    op_type: "_aten_sum_dim_none"
    attribute {
      name: "keepdim"
      i: 0
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "sum_2"
    input: "convert_element_type_3"
    output: "div"
    name: "aten_div_34"
    op_type: "aten_div"
    domain: "pkg.onnxscript.torch_lib"
  }
  name: "main_graph"
  initializer {
    dims: 10000
    dims: 256
    data_type: 1
    name: "model.decoder.embed_tokens.weight"
    raw_data: ""
  }
  initializer {
    dims: 1026
    dims: 256
    data_type: 1
    name: "model.decoder.embed_positions.weights"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.q_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.q_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.k_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.k_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.v_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.v_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.out_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn.out_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.self_attn_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 2048
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.fc1.weight"
    raw_data: ""
  }
  initializer {
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.0.fc1.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.0.fc2.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.fc2.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.final_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.0.final_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.q_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.q_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.k_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.k_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.v_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.v_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.out_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn.out_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.self_attn_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 2048
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.fc1.weight"
    raw_data: ""
  }
  initializer {
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.1.fc1.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.1.fc2.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.fc2.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.final_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.1.final_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.q_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.q_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.k_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.k_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.v_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.v_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.out_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn.out_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.self_attn_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 2048
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.fc1.weight"
    raw_data: ""
  }
  initializer {
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.2.fc1.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.2.fc2.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.fc2.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.final_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.2.final_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.q_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.q_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.k_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.k_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.v_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.v_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.out_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn.out_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.self_attn_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 2048
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.fc1.weight"
    raw_data: ""
  }
  initializer {
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.3.fc1.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.3.fc2.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.fc2.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.final_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.3.final_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.q_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.q_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.k_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.k_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.v_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.v_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.out_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn.out_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.self_attn_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 2048
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.fc1.weight"
    raw_data: ""
  }
  initializer {
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.4.fc1.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.4.fc2.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.fc2.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.final_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.4.final_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.q_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.q_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.k_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.k_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.v_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.v_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.out_proj.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn.out_proj.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.self_attn_layer_norm.bias"
    raw_data: ""
  }
  initializer {
    dims: 2048
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.fc1.weight"
    raw_data: ""
  }
  initializer {
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.5.fc1.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    dims: 2048
    data_type: 1
    name: "model.decoder.layers.5.fc2.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.fc2.bias"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.final_layer_norm.weight"
    raw_data: ""
  }
  initializer {
    dims: 256
    data_type: 1
    name: "model.decoder.layers.5.final_layer_norm.bias"
    raw_data: ""
  }
  input {
    name: "l_input_ids_"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  input {
    name: "l_labels_"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  output {
    name: "div"
    type {
      tensor_type {
        elem_type: 1
        shape {
        }
      }
    }
  }
  output {
    name: "lm_head_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 10000
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  output {
    name: "model_decoder_1_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.embed_tokens.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 10000
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.embed_positions.weights"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1026
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.q_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.q_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.k_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.k_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.v_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.v_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.out_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn.out_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.self_attn_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.fc1.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.fc1.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.fc2.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.fc2.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.final_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.0.final_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.q_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.q_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.k_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.k_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.v_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.v_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.out_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn.out_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.self_attn_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.fc1.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.fc1.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.fc2.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.fc2.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.final_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.1.final_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.q_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.q_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.k_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.k_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.v_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.v_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.out_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn.out_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.self_attn_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.fc1.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.fc1.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.fc2.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.fc2.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.final_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.2.final_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.q_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.q_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.k_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.k_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.v_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.v_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.out_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn.out_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.self_attn_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.fc1.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.fc1.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.fc2.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.fc2.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.final_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.3.final_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.q_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.q_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.k_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.k_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.v_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.v_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.out_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn.out_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.self_attn_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.fc1.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.fc1.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.fc2.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.fc2.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.final_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.4.final_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.q_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.q_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.k_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.k_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.v_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.v_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.out_proj.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn.out_proj.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.self_attn_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.fc1.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.fc1.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.fc2.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.fc2.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.final_layer_norm.weight"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model.decoder.layers.5.final_layer_norm.bias"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "model_decoder_1_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "_val_114"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 2
          }
        }
      }
    }
  }
  value_info {
    name: "view_138"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 10000
          }
        }
      }
    }
  }
  value_info {
    name: "_val_116"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "view_139"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "_log_softmax"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 10000
          }
        }
      }
    }
  }
  value_info {
    name: "_val_119"
    type {
      tensor_type {
        elem_type: 7
        shape {
        }
      }
    }
  }
  value_info {
    name: "ne_1"
    type {
      tensor_type {
        elem_type: 9
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "_val_121"
    type {
      tensor_type {
        elem_type: 7
        shape {
        }
      }
    }
  }
  value_info {
    name: "scalar_tensor"
    type {
      tensor_type {
        elem_type: 7
        shape {
        }
      }
    }
  }
  value_info {
    name: "where"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "unsqueeze_4"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "gather"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "squeeze"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "neg"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "_val_128"
    type {
      tensor_type {
        elem_type: 7
        shape {
        }
      }
    }
  }
  value_info {
    name: "ne_2"
    type {
      tensor_type {
        elem_type: 9
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "_val_130"
    type {
      tensor_type {
        elem_type: 7
        shape {
        }
      }
    }
  }
  value_info {
    name: "scalar_tensor_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
        }
      }
    }
  }
  value_info {
    name: "where_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "_val_133"
    type {
      tensor_type {
        elem_type: 7
        shape {
        }
      }
    }
  }
  value_info {
    name: "ne_3"
    type {
      tensor_type {
        elem_type: 9
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "convert_element_type_default_1"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "sum_1"
    type {
      tensor_type {
        elem_type: 7
        shape {
        }
      }
    }
  }
  value_info {
    name: "convert_element_type_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
        }
      }
    }
  }
  value_info {
    name: "sum_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_sparse_Embedding_model_decoder_embed_tokens_1/view"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_sparse_Embedding_model_decoder_embed_tokens_1/embedding"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/view"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/ne"
    type {
      tensor_type {
        elem_type: 9
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/convert_element_type"
    type {
      tensor_type {
        elem_type: 6
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/convert_element_type_default"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/cumsum"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/convert_element_type_1"
    type {
      tensor_type {
        elem_type: 6
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/scalar_tensor_default"
    type {
      tensor_type {
        elem_type: 6
        shape {
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/add_1"
    type {
      tensor_type {
        elem_type: 6
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/mul_1"
    type {
      tensor_type {
        elem_type: 6
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/convert_element_type_2"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/add_2"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/view_2"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/index_select"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/view_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/detach"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1/detach_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1/clone"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1/view_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1/t"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1/addmm"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1/view_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1/clone"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1/view_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1/t_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1/addmm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1/view_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1/clone"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1/view_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1/t_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1/addmm_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1/view_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1/view_19"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1/view_20"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1/t_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1/addmm_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1/view_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/clone"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/masked_fill"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/model_decoder_layers_0_self_attn_q_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/mul_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/model_decoder_layers_0_self_attn_k_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/transpose"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/clone_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/model_decoder_layers_0_self_attn_v_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/transpose_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/clone_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/transpose_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/clone_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_13"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_14"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/transpose_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/bmm"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_16"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/unsqueeze_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/unsqueeze_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/slice_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/slice_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/add_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_17"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/_softmax"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/clone_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/bmm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/transpose_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/clone_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/view_19"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1/model_decoder_layers_0_self_attn_out_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_self_attn_layer_norm_1/add_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_self_attn_layer_norm_1/native_layer_norm"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_self_attn_layer_norm_1/native_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_self_attn_layer_norm_1/native_layer_norm_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1/getitem"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1/view_22"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1/t_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1/addmm_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1/view_23"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_0_activation_fn_1/view_23"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_0_activation_fn_1/relu"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1/clone_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1/view_24"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1/t_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1/addmm_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1/view_25"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_final_layer_norm_1/add_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_final_layer_norm_1/native_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_final_layer_norm_1/native_layer_norm_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_final_layer_norm_1/native_layer_norm_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/clone"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/masked_fill"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_self_attn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_self_attn_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_self_attn_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_self_attn_1_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/clone_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/add_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_self_attn_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_fc1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_activation_fn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/clone_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_fc2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/clone_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/add_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1/model_decoder_layers_0_final_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1/getitem_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1/view_26"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1/t_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1/addmm_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1/view_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1/getitem_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1/view_28"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1/t_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1/addmm_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1/view_29"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1/getitem_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1/view_31"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1/t_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1/addmm_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1/view_32"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1/view_41"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1/view_42"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1/t_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1/addmm_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1/view_43"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/getitem_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/model_decoder_layers_1_self_attn_q_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/mul_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/model_decoder_layers_1_self_attn_k_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_30"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/transpose_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/clone_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/model_decoder_layers_1_self_attn_v_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_33"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/transpose_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/clone_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_34"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/transpose_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/clone_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_35"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_36"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_37"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/transpose_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/bmm_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_38"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/add_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_39"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/_softmax_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/clone_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/bmm_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_40"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/transpose_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/clone_13"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/view_41"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1/model_decoder_layers_1_self_attn_out_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_self_attn_layer_norm_1/add_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_self_attn_layer_norm_1/native_layer_norm_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_self_attn_layer_norm_1/native_layer_norm_2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_self_attn_layer_norm_1/native_layer_norm_2_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1/getitem_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1/view_44"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1/t_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1/addmm_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1/view_45"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_1_activation_fn_1/view_45"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_1_activation_fn_1/relu_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1/clone_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1/view_46"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1/t_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1/addmm_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1/view_47"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_final_layer_norm_1/add_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_final_layer_norm_1/native_layer_norm_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_final_layer_norm_1/native_layer_norm_3_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_final_layer_norm_1/native_layer_norm_3_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/getitem_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_self_attn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_self_attn_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_self_attn_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/clone_14"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/add_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_self_attn_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_fc1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_activation_fn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/clone_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_fc2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/clone_16"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/add_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1/model_decoder_layers_1_final_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1/getitem_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1/view_48"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1/t_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1/addmm_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1/view_49"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1/getitem_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1/view_50"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1/t_13"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1/addmm_13"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1/view_51"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1/getitem_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1/view_53"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1/t_14"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1/addmm_14"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1/view_54"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1/view_63"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1/view_64"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1/t_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1/addmm_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1/view_65"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/getitem_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/model_decoder_layers_2_self_attn_q_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/mul_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/model_decoder_layers_2_self_attn_k_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_52"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/transpose_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/clone_17"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/model_decoder_layers_2_self_attn_v_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_55"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/transpose_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/clone_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_56"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/transpose_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/clone_19"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_57"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_58"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_59"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/transpose_13"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/bmm_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_60"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/add_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_61"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/_softmax_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/clone_20"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/bmm_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_62"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/transpose_14"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/clone_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/view_63"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1/model_decoder_layers_2_self_attn_out_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_self_attn_layer_norm_1/add_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_self_attn_layer_norm_1/native_layer_norm_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_self_attn_layer_norm_1/native_layer_norm_4_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_self_attn_layer_norm_1/native_layer_norm_4_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1/getitem_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1/view_66"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1/t_16"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1/addmm_16"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1/view_67"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_2_activation_fn_1/view_67"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_2_activation_fn_1/relu_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1/clone_23"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1/view_68"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1/t_17"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1/addmm_17"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1/view_69"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_final_layer_norm_1/add_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_final_layer_norm_1/native_layer_norm_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_final_layer_norm_1/native_layer_norm_5_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_final_layer_norm_1/native_layer_norm_5_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/getitem_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_self_attn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_self_attn_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_self_attn_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/clone_22"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/add_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_self_attn_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_fc1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_activation_fn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/clone_23"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_fc2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/clone_24"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/add_12"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1/model_decoder_layers_2_final_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1/getitem_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1/view_70"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1/t_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1/addmm_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1/view_71"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1/getitem_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1/view_72"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1/t_19"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1/addmm_19"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1/view_73"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1/getitem_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1/view_75"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1/t_20"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1/addmm_20"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1/view_76"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1/view_85"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1/view_86"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1/t_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1/addmm_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1/view_87"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/getitem_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/model_decoder_layers_3_self_attn_q_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/mul_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/model_decoder_layers_3_self_attn_k_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_74"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/transpose_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/clone_25"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/model_decoder_layers_3_self_attn_v_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_77"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/transpose_16"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/clone_26"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_78"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/transpose_17"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/clone_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_79"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_80"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_81"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/transpose_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/bmm_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_82"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/add_13"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_83"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/_softmax_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/clone_28"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/bmm_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_84"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/transpose_19"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/clone_29"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/view_85"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1/model_decoder_layers_3_self_attn_out_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_self_attn_layer_norm_1/add_14"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_self_attn_layer_norm_1/native_layer_norm_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_self_attn_layer_norm_1/native_layer_norm_6_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_self_attn_layer_norm_1/native_layer_norm_6_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1/getitem_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1/view_88"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1/t_22"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1/addmm_22"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1/view_89"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_3_activation_fn_1/view_89"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_3_activation_fn_1/relu_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1/clone_31"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1/view_90"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1/t_23"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1/addmm_23"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1/view_91"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_final_layer_norm_1/add_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_final_layer_norm_1/native_layer_norm_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_final_layer_norm_1/native_layer_norm_7_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_final_layer_norm_1/native_layer_norm_7_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/getitem_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_self_attn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_self_attn_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_self_attn_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/clone_30"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/add_14"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_self_attn_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_fc1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_activation_fn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/clone_31"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_fc2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/clone_32"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/add_15"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1/model_decoder_layers_3_final_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1/getitem_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1/view_92"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1/t_24"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1/addmm_24"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1/view_93"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1/getitem_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1/view_94"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1/t_25"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1/addmm_25"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1/view_95"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1/getitem_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1/view_97"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1/t_26"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1/addmm_26"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1/view_98"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1/view_107"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1/view_108"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1/t_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1/addmm_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1/view_109"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/getitem_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/model_decoder_layers_4_self_attn_q_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/mul_6"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/model_decoder_layers_4_self_attn_k_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_96"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/transpose_20"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/clone_33"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/model_decoder_layers_4_self_attn_v_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_99"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/transpose_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/clone_34"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_100"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/transpose_22"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/clone_35"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_101"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_102"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_103"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/transpose_23"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/bmm_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_104"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/add_16"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_105"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/_softmax_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/clone_36"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/bmm_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_106"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/transpose_24"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/clone_37"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/view_107"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1/model_decoder_layers_4_self_attn_out_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_self_attn_layer_norm_1/add_17"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_self_attn_layer_norm_1/native_layer_norm_8"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_self_attn_layer_norm_1/native_layer_norm_8_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_self_attn_layer_norm_1/native_layer_norm_8_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1/getitem_24"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1/view_110"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1/t_28"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1/addmm_28"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1/view_111"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_4_activation_fn_1/view_111"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_4_activation_fn_1/relu_4"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1/clone_39"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1/view_112"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1/t_29"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1/addmm_29"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1/view_113"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_final_layer_norm_1/add_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_final_layer_norm_1/native_layer_norm_9"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_final_layer_norm_1/native_layer_norm_9_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_final_layer_norm_1/native_layer_norm_9_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/getitem_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_self_attn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_self_attn_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_self_attn_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/clone_38"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/add_17"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_self_attn_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_fc1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_activation_fn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/clone_39"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_fc2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/clone_40"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/add_18"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1/model_decoder_layers_4_final_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1/getitem_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1/view_114"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1/t_30"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1/addmm_30"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1/view_115"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1/getitem_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1/view_116"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1/t_31"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1/addmm_31"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1/view_117"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1/getitem_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1/view_119"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1/t_32"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1/addmm_32"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1/view_120"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1/view_129"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1/view_130"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1/t_33"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1/addmm_33"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1/view_131"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/getitem_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/model_decoder_layers_5_self_attn_q_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/mul_7"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/model_decoder_layers_5_self_attn_k_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_118"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/transpose_25"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/clone_41"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/model_decoder_layers_5_self_attn_v_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_121"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/transpose_26"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/clone_42"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_122"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/transpose_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/clone_43"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_123"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_124"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_125"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/transpose_28"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/bmm_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_126"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/add_19"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_127"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/_softmax_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/clone_44"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/bmm_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_128"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/transpose_29"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/clone_45"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/view_129"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1/model_decoder_layers_5_self_attn_out_proj_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_self_attn_layer_norm_1/add_20"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_self_attn_layer_norm_1/native_layer_norm_10"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_self_attn_layer_norm_1/native_layer_norm_10_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_self_attn_layer_norm_1/native_layer_norm_10_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1/getitem_30"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1/view_132"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1/t_34"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1/addmm_34"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1/view_133"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_5_activation_fn_1/view_133"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_activation_ReLU_model_decoder_layers_5_activation_fn_1/relu_5"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1/clone_47"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1/view_134"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1/t_35"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 2048
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1/addmm_35"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1/view_135"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_final_layer_norm_1/add_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_final_layer_norm_1/native_layer_norm_11"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_final_layer_norm_1/native_layer_norm_11_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_final_layer_norm_1/native_layer_norm_11_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/getitem_27"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/expand_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_self_attn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_self_attn_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_self_attn_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/clone_46"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/add_20"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_self_attn_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_fc1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_activation_fn_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/clone_47"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 2048
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_fc2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/clone_48"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/add_21"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1/model_decoder_layers_5_final_layer_norm_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/l_input_ids_"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/view"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_embed_tokens_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/mul"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/full"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/arange"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/add"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/view_1"
    type {
      tensor_type {
        elem_type: 7
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 1
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/lt"
    type {
      tensor_type {
        elem_type: 9
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/masked_fill"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_embed_positions_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/add_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/clone"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_0_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_0_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_0_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 128
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_0_1_3"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_1_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_1_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_2_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_2_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_2_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_3_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_3_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_3_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_4_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_4_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_4_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_5_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_5_1_1"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 64
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.transformers.4.34.0.dev0::transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1/model_decoder_layers_5_1_2"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_lm_head_1/getitem_33"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_lm_head_1/t_36"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 256
          }
          dim {
            dim_value: 10000
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_lm_head_1/view_136"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 256
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_lm_head_1/mm"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 10000
          }
        }
      }
    }
  }
  value_info {
    name: "pkg.torch.2.2.0a0+git63d65dd::torch_nn_modules_linear_Linear_lm_head_1/view_137"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 1
          }
          dim {
            dim_value: 128
          }
          dim {
            dim_value: 10000
          }
        }
      }
    }
  }
}
opset_import {
  domain: "pkg.onnxscript.torch_lib"
  version: 1
}
opset_import {
  domain: "pkg.torch.2.2.0a0+git63d65dd"
  version: 1
}
opset_import {
  domain: "pkg.transformers.4.34.0.dev0"
  version: 1
}
opset_import {
  domain: ""
  version: 18
}
opset_import {
  domain: "pkg.onnxscript.torch_lib.common"
  version: 1
}
functions {
  name: "aten_embedding"
  input: "weight"
  input: "indices"
  output: "return_val"
  node {
    input: "weight"
    input: "indices"
    output: "return_val"
    name: "n0"
    op_type: "Gather"
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "padding_idx"
    i: -1
    type: INT
  }
  attribute_proto {
    name: "scale_grad_by_freq"
    i: 0
    type: INT
  }
  attribute_proto {
    name: "sparse"
    i: 0
    type: INT
  }
}
functions {
  name: "torch_nn_modules_sparse_Embedding_model_decoder_embed_tokens_1"
  input: "view"
  input: "model.decoder.embed_tokens.weight"
  output: "embedding"
  node {
    input: "model.decoder.embed_tokens.weight"
    input: "view"
    output: "embedding"
    name: "aten_embedding_0"
    op_type: "aten_embedding"
    attribute {
      name: "padding_idx"
      i: 1
      type: INT
    }
    attribute {
      name: "scale_grad_by_freq"
      i: 0
      type: INT
    }
    attribute {
      name: "sparse"
      i: 0
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "aten_ne"
  input: "self"
  input: "other"
  output: "return_val"
  node {
    input: "self"
    input: "other"
    output: "tmp"
    name: "n0"
    op_type: "Equal"
  }
  node {
    input: "tmp"
    output: "return_val"
    name: "n1"
    op_type: "Not"
  }
  doc_string: "ne.Tensor(Tensor self, Tensor other) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "prims_convert_element_type"
  input: "a"
  output: "return_val"
  attribute: "dtype"
  node {
    input: "a"
    output: "return_val"
    name: "n0"
    op_type: "Cast"
    attribute {
      name: "to"
      type: INT
      ref_attr_name: "dtype"
    }
  }
  doc_string: "convert_element_type(Tensor a, ScalarType dtype) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "_aten_cumsum_onnx"
  input: "self"
  input: "dim"
  output: "result_2"
  node {
    input: "self"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_0"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 0
        name: "int64_0"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_0"
    input: "tmp_0"
    output: "int64_0_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "tmp_0"
    input: "int64_0_cast"
    output: "cond"
    name: "n4"
    op_type: "Equal"
  }
  node {
    input: "cond"
    output: "result_2"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "self"
          output: "result"
          name: "n0"
          op_type: "Identity"
        }
        name: "thenGraph_5"
        output {
          name: "result"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          input: "dim"
          output: "result_1"
          name: "n0"
          op_type: "CumSum"
        }
        name: "elseGraph_5"
        output {
          name: "result_1"
        }
      }
      type: GRAPH
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_scalar_tensor_sym_number"
  input: "s"
  output: "return_val"
  node {
    input: "s"
    output: "return_val"
    name: "n0"
    op_type: "Cast"
    attribute {
      name: "to"
      type: INT
      ref_attr_name: "dtype"
    }
  }
  doc_string: "scalar_tensor(Scalar s, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "dtype"
    i: 1
    type: INT
  }
}
functions {
  name: "aten_add"
  input: "self"
  input: "other"
  output: "return_val"
  node {
    output: "alpha"
    name: "n0"
    op_type: "Constant"
    attribute {
      name: "value_float"
      type: FLOAT
      ref_attr_name: "alpha"
    }
  }
  node {
    input: "alpha"
    input: "other"
    output: "alpha_0"
    name: "n1"
    op_type: "CastLike"
  }
  node {
    input: "other"
    input: "alpha_0"
    output: "other_1"
    name: "n2"
    op_type: "Mul"
  }
  node {
    input: "self"
    input: "other_1"
    output: "return_val"
    name: "n3"
    op_type: "Add"
  }
  doc_string: "add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "alpha"
    f: 1.0
    type: FLOAT
  }
}
functions {
  name: "aten_mul"
  input: "self"
  input: "other"
  output: "return_val"
  node {
    input: "other"
    input: "self"
    output: "other_0"
    name: "n0"
    op_type: "CastLike"
  }
  node {
    input: "self"
    input: "other_0"
    output: "return_val"
    name: "n1"
    op_type: "Mul"
  }
  doc_string: "mul.Tensor(Tensor self, Tensor other) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_view"
  input: "self"
  input: "size"
  output: "return_val"
  node {
    input: "size"
    output: "size_0"
    name: "n0"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    input: "self"
    input: "size_0"
    output: "return_val"
    name: "n1"
    op_type: "Reshape"
  }
  doc_string: "view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_index_select"
  input: "self"
  input: "index"
  output: "result_10"
  attribute: "dim"
  node {
    input: "self"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_0"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 0
        name: "int64_0"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_0"
    input: "tmp_0"
    output: "int64_0_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "tmp_0"
    input: "int64_0_cast"
    output: "self_is_scalar"
    name: "n4"
    op_type: "Equal"
  }
  node {
    input: "self_is_scalar"
    output: "self_4"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          output: "tmp_1"
          name: "n0"
          op_type: "Constant"
          attribute {
            name: "value_ints"
            ints: -1
            type: INTS
          }
        }
        node {
          input: "self"
          input: "tmp_1"
          output: "self_2"
          name: "n1"
          op_type: "Reshape"
        }
        name: "thenGraph_6"
        output {
          name: "self_2"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          output: "self_3"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_6"
        output {
          name: "self_3"
        }
      }
      type: GRAPH
    }
  }
  node {
    output: "tmp_5"
    name: "n6"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "index"
    input: "tmp_5"
    output: "index_6"
    name: "n7"
    op_type: "Reshape"
  }
  node {
    input: "index_6"
    output: "index_7"
    name: "n8"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    input: "self_4"
    input: "index_7"
    output: "result"
    name: "n9"
    op_type: "Gather"
    attribute {
      name: "axis"
      type: INT
      ref_attr_name: "dim"
    }
  }
  node {
    input: "self_is_scalar"
    output: "result_10"
    name: "n10"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "result"
          output: "result_8"
          name: "n0"
          op_type: "Squeeze"
        }
        name: "thenGraph_14"
        output {
          name: "result_8"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "result"
          output: "result_9"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_14"
        output {
          name: "result_9"
        }
      }
      type: GRAPH
    }
  }
  doc_string: "index_select(Tensor self, int dim, Tensor index) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_detach"
  input: "self"
  output: "return_val"
  node {
    input: "self"
    output: "return_val"
    name: "n0"
    op_type: "Identity"
  }
  doc_string: "detach(Tensor(a) self) -> Tensor(a)"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1"
  input: "view"
  input: "model.decoder.embed_positions.weights"
  output: "detach_1"
  node {
    output: "_val_1"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "view"
    input: "_val_1"
    output: "ne"
    name: "aten_ne_7"
    op_type: "aten_ne"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "ne"
    output: "convert_element_type"
    name: "prims_convert_element_type_8"
    op_type: "prims_convert_element_type"
    attribute {
      name: "dtype"
      i: 6
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "convert_element_type"
    output: "convert_element_type_default"
    name: "prims_convert_element_type_9"
    op_type: "prims_convert_element_type"
    attribute {
      name: "dtype"
      i: 7
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_5"
    name: "Constant_10"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "convert_element_type_default"
    input: "_val_5"
    output: "cumsum"
    name: "_aten_cumsum_onnx_11"
    op_type: "_aten_cumsum_onnx"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "cumsum"
    output: "convert_element_type_1"
    name: "prims_convert_element_type_12"
    op_type: "prims_convert_element_type"
    attribute {
      name: "dtype"
      i: 6
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_8"
    name: "Constant_13"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\000\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_8"
    output: "scalar_tensor_default"
    name: "aten_scalar_tensor_sym_number_14"
    op_type: "aten_scalar_tensor_sym_number"
    attribute {
      name: "dtype"
      i: 6
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "convert_element_type_1"
    input: "scalar_tensor_default"
    output: "add_1"
    name: "aten_add_15"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_1"
    input: "convert_element_type"
    output: "mul_1"
    name: "aten_mul_16"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "mul_1"
    output: "convert_element_type_2"
    name: "prims_convert_element_type_17"
    op_type: "prims_convert_element_type"
    attribute {
      name: "dtype"
      i: 7
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_13"
    name: "Constant_18"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "convert_element_type_2"
    input: "_val_13"
    output: "add_2"
    name: "aten_add_19"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_15"
    name: "Constant_20"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 1
        data_type: 7
        raw_data: "\377\377\377\377\377\377\377\377"
      }
      type: TENSOR
    }
  }
  node {
    input: "add_2"
    input: "_val_15"
    output: "view_2"
    name: "aten_view_21"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.embed_positions.weights"
    input: "view_2"
    output: "index_select"
    name: "aten_index_select_22"
    op_type: "aten_index_select"
    attribute {
      name: "dim"
      i: 0
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_19"
    name: "Constant_23"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377"
      }
      type: TENSOR
    }
  }
  node {
    input: "index_select"
    input: "_val_19"
    output: "view_3"
    name: "aten_view_24"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_3"
    output: "detach"
    name: "aten_detach_25"
    op_type: "aten_detach"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "detach"
    output: "detach_1"
    name: "aten_detach_26"
    op_type: "aten_detach"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "aten_t"
  input: "self"
  output: "result_1"
  node {
    input: "self"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "rank"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_2"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 2
        name: "int64_2"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_2"
    input: "rank"
    output: "int64_2_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "rank"
    input: "int64_2_cast"
    output: "cond"
    name: "n4"
    op_type: "Equal"
  }
  node {
    input: "cond"
    output: "result_1"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "self"
          output: "result"
          name: "n0"
          op_type: "Transpose"
          attribute {
            name: "perm"
            ints: 1
            ints: 0
            type: INTS
          }
        }
        name: "thenGraph_6"
        output {
          name: "result"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          output: "result_0"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_6"
        output {
          name: "result_0"
        }
      }
      type: GRAPH
    }
  }
  doc_string: "t(Tensor(a) self) -> Tensor(a)"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_addmm"
  input: "self"
  input: "mat1"
  input: "mat2"
  output: "return_val"
  node {
    input: "mat1"
    input: "mat2"
    input: "self"
    output: "return_val"
    name: "n0"
    op_type: "Gemm"
    attribute {
      name: "alpha"
      type: FLOAT
      ref_attr_name: "alpha"
    }
    attribute {
      name: "beta"
      type: FLOAT
      ref_attr_name: "beta"
    }
  }
  doc_string: "addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "beta"
    f: 1.0
    type: FLOAT
  }
  attribute_proto {
    name: "alpha"
    f: 1.0
    type: FLOAT
  }
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1"
  input: "clone"
  input: "model.decoder.layers.0.self_attn.q_proj.weight"
  input: "model.decoder.layers.0.self_attn.q_proj.bias"
  output: "view_5"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone"
    input: "_val_1"
    output: "view_4"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.q_proj.weight"
    output: "t"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.q_proj.bias"
    input: "view_4"
    input: "t"
    output: "addmm"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm"
    input: "_val_7"
    output: "view_5"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1"
  input: "clone"
  input: "model.decoder.layers.0.self_attn.k_proj.weight"
  input: "model.decoder.layers.0.self_attn.k_proj.bias"
  output: "view_7"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone"
    input: "_val_1"
    output: "view_6"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.k_proj.weight"
    output: "t_1"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.k_proj.bias"
    input: "view_6"
    input: "t_1"
    output: "addmm_1"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_1"
    input: "_val_7"
    output: "view_7"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1"
  input: "clone"
  input: "model.decoder.layers.0.self_attn.v_proj.weight"
  input: "model.decoder.layers.0.self_attn.v_proj.bias"
  output: "view_10"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone"
    input: "_val_1"
    output: "view_9"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.v_proj.weight"
    output: "t_2"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.v_proj.bias"
    input: "view_9"
    input: "t_2"
    output: "addmm_2"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_2"
    input: "_val_7"
    output: "view_10"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1"
  input: "view_19"
  input: "model.decoder.layers.0.self_attn.out_proj.weight"
  input: "model.decoder.layers.0.self_attn.out_proj.bias"
  output: "view_21"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_19"
    input: "_val_1"
    output: "view_20"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.out_proj.weight"
    output: "t_3"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.self_attn.out_proj.bias"
    input: "view_20"
    input: "t_3"
    output: "addmm_3"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_3"
    input: "_val_7"
    output: "view_21"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "aten_clone"
  input: "self"
  output: "return_val"
  node {
    input: "self"
    output: "return_val"
    name: "n0"
    op_type: "Identity"
  }
  doc_string: "clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "memory_format"
    s: ""
    type: STRING
  }
}
functions {
  name: "aten_bmm"
  input: "self"
  input: "mat2"
  output: "return_val"
  node {
    input: "self"
    input: "mat2"
    output: "return_val"
    name: "n0"
    op_type: "MatMul"
  }
  doc_string: "bmm(Tensor self, Tensor mat2) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_unsqueeze"
  input: "self"
  output: "return_val"
  attribute: "dim"
  node {
    output: "dim"
    name: "n0"
    op_type: "Constant"
    attribute {
      name: "value_int"
      type: INT
      ref_attr_name: "dim"
    }
  }
  node {
    input: "dim"
    output: "dim_0"
    name: "n1"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    input: "self"
    input: "dim_0"
    output: "return_val"
    name: "n2"
    op_type: "Unsqueeze"
  }
  doc_string: "unsqueeze(Tensor(a) self, int dim) -> Tensor(a)"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_expand"
  input: "self"
  input: "size"
  output: "return_val"
  node {
    input: "size"
    output: "size_0"
    name: "n0"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    input: "size_0"
    output: "size_1"
    name: "n1"
    op_type: "Abs"
  }
  node {
    input: "self"
    input: "size_1"
    output: "return_val"
    name: "n2"
    op_type: "Expand"
  }
  doc_string: "expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_softmax_no_dtype"
  input: "self"
  output: "result_7"
  attribute: "dim"
  node {
    input: "self"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_0"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 0
        name: "int64_0"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_0"
    input: "tmp_0"
    output: "int64_0_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "tmp_0"
    input: "int64_0_cast"
    output: "self_is_scalar"
    name: "n4"
    op_type: "Equal"
  }
  node {
    input: "self_is_scalar"
    output: "self_4"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          output: "tmp_1"
          name: "n0"
          op_type: "Constant"
          attribute {
            name: "value_ints"
            ints: 0
            type: INTS
          }
        }
        node {
          input: "self"
          input: "tmp_1"
          output: "self_2"
          name: "n1"
          op_type: "Unsqueeze"
        }
        name: "thenGraph_6"
        output {
          name: "self_2"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          output: "self_3"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_6"
        output {
          name: "self_3"
        }
      }
      type: GRAPH
    }
  }
  node {
    input: "self_4"
    output: "result"
    name: "n6"
    op_type: "Softmax"
    attribute {
      name: "axis"
      type: INT
      ref_attr_name: "dim"
    }
  }
  node {
    input: "self_is_scalar"
    output: "result_7"
    name: "n7"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "result"
          output: "result_5"
          name: "n0"
          op_type: "Squeeze"
        }
        name: "thenGraph_9"
        output {
          name: "result_5"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "result"
          output: "result_6"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_9"
        output {
          name: "result_6"
        }
      }
      type: GRAPH
    }
  }
  doc_string: "softmax(Tensor self, int dim, ScalarType? dtype=None) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1"
  input: "clone"
  input: "masked_fill"
  input: "model.decoder.layers.0.self_attn.q_proj.weight"
  input: "model.decoder.layers.0.self_attn.q_proj.bias"
  input: "model.decoder.layers.0.self_attn.k_proj.weight"
  input: "model.decoder.layers.0.self_attn.k_proj.bias"
  input: "model.decoder.layers.0.self_attn.v_proj.weight"
  input: "model.decoder.layers.0.self_attn.v_proj.bias"
  input: "model.decoder.layers.0.self_attn.out_proj.weight"
  input: "model.decoder.layers.0.self_attn.out_proj.bias"
  output: "clone_1"
  output: "clone_2"
  output: "expand_1"
  output: "model_decoder_layers_0_self_attn_out_proj_1"
  node {
    input: "clone"
    input: "model.decoder.layers.0.self_attn.q_proj.weight"
    input: "model.decoder.layers.0.self_attn.q_proj.bias"
    output: "model_decoder_layers_0_self_attn_q_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1_20"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_q_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_5"
    name: "Constant_21"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\000>"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_0_self_attn_q_proj_1"
    input: "_val_5"
    output: "mul_2"
    name: "aten_mul_22"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone"
    input: "model.decoder.layers.0.self_attn.k_proj.weight"
    input: "model.decoder.layers.0.self_attn.k_proj.bias"
    output: "model_decoder_layers_0_self_attn_k_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1_23"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_k_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_10"
    name: "Constant_24"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_0_self_attn_k_proj_1"
    input: "_val_10"
    output: "view_8"
    name: "aten_view_25"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_8"
    output: "transpose"
    name: "Transpose_26"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose"
    output: "clone_1"
    name: "aten_clone_27"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone"
    input: "model.decoder.layers.0.self_attn.v_proj.weight"
    input: "model.decoder.layers.0.self_attn.v_proj.bias"
    output: "model_decoder_layers_0_self_attn_v_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1_28"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_v_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_17"
    name: "Constant_29"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_0_self_attn_v_proj_1"
    input: "_val_17"
    output: "view_11"
    name: "aten_view_30"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_11"
    output: "transpose_1"
    name: "Transpose_31"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_1"
    output: "clone_2"
    name: "aten_clone_32"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_21"
    name: "Constant_33"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "mul_2"
    input: "_val_21"
    output: "view_12"
    name: "aten_view_34"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_12"
    output: "transpose_2"
    name: "Transpose_35"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_2"
    output: "clone_3"
    name: "aten_clone_36"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_25"
    name: "Constant_37"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_3"
    input: "_val_25"
    output: "view_13"
    name: "aten_view_38"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_27"
    name: "Constant_39"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_1"
    input: "_val_27"
    output: "view_14"
    name: "aten_view_40"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_29"
    name: "Constant_41"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_2"
    input: "_val_29"
    output: "view_15"
    name: "aten_view_42"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_14"
    output: "transpose_3"
    name: "Transpose_43"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      type: INTS
    }
  }
  node {
    input: "view_13"
    input: "transpose_3"
    output: "bmm"
    name: "aten_bmm_44"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_33"
    name: "Constant_45"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm"
    input: "_val_33"
    output: "view_16"
    name: "aten_view_46"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "masked_fill"
    output: "unsqueeze_2"
    name: "aten_unsqueeze_47"
    op_type: "aten_unsqueeze"
    attribute {
      name: "dim"
      i: 0
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "unsqueeze_2"
    output: "unsqueeze_3"
    name: "aten_unsqueeze_48"
    op_type: "aten_unsqueeze"
    attribute {
      name: "dim"
      i: 1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_37"
    name: "Constant_49"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\000\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_37"
    output: "_val_38"
    name: "Cast_50"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_39"
    name: "Constant_51"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_38"
    input: "_val_39"
    output: "_val_40"
    name: "Reshape_52"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    output: "_val_41"
    name: "Constant_53"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\377\377\377\377\377\377\377\177"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_41"
    output: "_val_42"
    name: "Cast_54"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_43"
    name: "Constant_55"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_42"
    input: "_val_43"
    output: "_val_44"
    name: "Reshape_56"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    output: "_val_45"
    name: "Constant_57"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\002\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_45"
    output: "_val_46"
    name: "Cast_58"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_47"
    name: "Constant_59"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_46"
    input: "_val_47"
    output: "_val_48"
    name: "Reshape_60"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    output: "_val_49"
    name: "Constant_61"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_49"
    output: "_val_50"
    name: "Cast_62"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_51"
    name: "Constant_63"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_50"
    input: "_val_51"
    output: "_val_52"
    name: "Reshape_64"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    input: "unsqueeze_3"
    input: "_val_40"
    input: "_val_44"
    input: "_val_48"
    input: "_val_52"
    output: "slice_3"
    name: "Slice_65"
    op_type: "Slice"
  }
  node {
    output: "_val_54"
    name: "Constant_66"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\000\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_54"
    output: "_val_55"
    name: "Cast_67"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_56"
    name: "Constant_68"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_55"
    input: "_val_56"
    output: "_val_57"
    name: "Reshape_69"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    output: "_val_58"
    name: "Constant_70"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\377\377\377\377\377\377\377\177"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_58"
    output: "_val_59"
    name: "Cast_71"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_60"
    name: "Constant_72"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_59"
    input: "_val_60"
    output: "_val_61"
    name: "Reshape_73"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    output: "_val_62"
    name: "Constant_74"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\003\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_62"
    output: "_val_63"
    name: "Cast_75"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_64"
    name: "Constant_76"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_63"
    input: "_val_64"
    output: "_val_65"
    name: "Reshape_77"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    output: "_val_66"
    name: "Constant_78"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_66"
    output: "_val_67"
    name: "Cast_79"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    output: "_val_68"
    name: "Constant_80"
    op_type: "Constant"
    attribute {
      name: "value_ints"
      ints: -1
      type: INTS
    }
  }
  node {
    input: "_val_67"
    input: "_val_68"
    output: "_val_69"
    name: "Reshape_81"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
  }
  node {
    input: "slice_3"
    input: "_val_57"
    input: "_val_61"
    input: "_val_65"
    input: "_val_69"
    output: "slice_4"
    name: "Slice_82"
    op_type: "Slice"
  }
  node {
    output: "_val_71"
    name: "Constant_83"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "slice_4"
    input: "_val_71"
    output: "expand_1"
    name: "aten_expand_84"
    op_type: "aten_expand"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_16"
    input: "expand_1"
    output: "add_4"
    name: "aten_add_85"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_74"
    name: "Constant_86"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "add_4"
    input: "_val_74"
    output: "view_17"
    name: "aten_view_87"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_17"
    output: "_softmax"
    name: "aten_softmax_no_dtype_88"
    op_type: "aten_softmax_no_dtype"
    attribute {
      name: "dim"
      i: -1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "_softmax"
    output: "clone_4"
    name: "aten_clone_89"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_4"
    input: "view_15"
    output: "bmm_1"
    name: "aten_bmm_90"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_79"
    name: "Constant_91"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_1"
    input: "_val_79"
    output: "view_18"
    name: "aten_view_92"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_18"
    output: "transpose_4"
    name: "Transpose_93"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_4"
    output: "clone_5"
    name: "aten_clone_94"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_83"
    name: "Constant_95"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_5"
    input: "_val_83"
    output: "view_19"
    name: "aten_view_96"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_19"
    input: "model.decoder.layers.0.self_attn.out_proj.weight"
    input: "model.decoder.layers.0.self_attn.out_proj.bias"
    output: "model_decoder_layers_0_self_attn_out_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1_97"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_0_self_attn_out_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_self_attn_layer_norm_1"
  input: "add_5"
  input: "model.decoder.layers.0.self_attn_layer_norm.weight"
  input: "model.decoder.layers.0.self_attn_layer_norm.bias"
  output: "native_layer_norm"
  node {
    input: "add_5"
    input: "model.decoder.layers.0.self_attn_layer_norm.weight"
    input: "model.decoder.layers.0.self_attn_layer_norm.bias"
    output: "native_layer_norm"
    output: "native_layer_norm_1"
    output: "native_layer_norm_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1"
  input: "getitem"
  input: "model.decoder.layers.0.fc1.weight"
  input: "model.decoder.layers.0.fc1.bias"
  output: "view_23"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem"
    input: "_val_1"
    output: "view_22"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.fc1.weight"
    output: "t_4"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.fc1.bias"
    input: "view_22"
    input: "t_4"
    output: "addmm_4"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_4"
    input: "_val_7"
    output: "view_23"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "aten_relu"
  input: "self"
  output: "return_val"
  node {
    input: "self"
    output: "return_val"
    name: "n0"
    op_type: "Relu"
  }
  doc_string: "relu(Tensor self) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "torch_nn_modules_activation_ReLU_model_decoder_layers_0_activation_fn_1"
  input: "view_23"
  output: "relu"
  node {
    input: "view_23"
    output: "relu"
    name: "aten_relu_0"
    op_type: "aten_relu"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1"
  input: "clone_7"
  input: "model.decoder.layers.0.fc2.weight"
  input: "model.decoder.layers.0.fc2.bias"
  output: "view_25"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_7"
    input: "_val_1"
    output: "view_24"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.fc2.weight"
    output: "t_5"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.0.fc2.bias"
    input: "view_24"
    input: "t_5"
    output: "addmm_5"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_5"
    input: "_val_7"
    output: "view_25"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_final_layer_norm_1"
  input: "add_6"
  input: "model.decoder.layers.0.final_layer_norm.weight"
  input: "model.decoder.layers.0.final_layer_norm.bias"
  output: "native_layer_norm_1"
  node {
    input: "add_6"
    input: "model.decoder.layers.0.final_layer_norm.weight"
    input: "model.decoder.layers.0.final_layer_norm.bias"
    output: "native_layer_norm_1"
    output: "native_layer_norm_1_1"
    output: "native_layer_norm_1_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1"
  input: "clone"
  input: "masked_fill"
  input: "model.decoder.layers.0.self_attn.q_proj.weight"
  input: "model.decoder.layers.0.self_attn.q_proj.bias"
  input: "model.decoder.layers.0.self_attn.k_proj.weight"
  input: "model.decoder.layers.0.self_attn.k_proj.bias"
  input: "model.decoder.layers.0.self_attn.v_proj.weight"
  input: "model.decoder.layers.0.self_attn.v_proj.bias"
  input: "model.decoder.layers.0.self_attn.out_proj.weight"
  input: "model.decoder.layers.0.self_attn.out_proj.bias"
  input: "model.decoder.layers.0.self_attn_layer_norm.weight"
  input: "model.decoder.layers.0.self_attn_layer_norm.bias"
  input: "model.decoder.layers.0.fc1.weight"
  input: "model.decoder.layers.0.fc1.bias"
  input: "model.decoder.layers.0.fc2.weight"
  input: "model.decoder.layers.0.fc2.bias"
  input: "model.decoder.layers.0.final_layer_norm.weight"
  input: "model.decoder.layers.0.final_layer_norm.bias"
  output: "model_decoder_layers_0_self_attn_1"
  output: "model_decoder_layers_0_self_attn_1_1"
  output: "model_decoder_layers_0_self_attn_1_2"
  output: "model_decoder_layers_0_final_layer_norm_1"
  node {
    input: "clone"
    input: "masked_fill"
    input: "model.decoder.layers.0.self_attn.q_proj.weight"
    input: "model.decoder.layers.0.self_attn.q_proj.bias"
    input: "model.decoder.layers.0.self_attn.k_proj.weight"
    input: "model.decoder.layers.0.self_attn.k_proj.bias"
    input: "model.decoder.layers.0.self_attn.v_proj.weight"
    input: "model.decoder.layers.0.self_attn.v_proj.bias"
    input: "model.decoder.layers.0.self_attn.out_proj.weight"
    input: "model.decoder.layers.0.self_attn.out_proj.bias"
    output: "model_decoder_layers_0_self_attn_1"
    output: "model_decoder_layers_0_self_attn_1_1"
    output: "model_decoder_layers_0_self_attn_1_2"
    output: "model_decoder_layers_0_self_attn_1_3"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1_0"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_0_self_attn_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_0_self_attn_1_3"
    output: "clone_6"
    name: "aten_clone_1"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone"
    input: "clone_6"
    output: "add_5"
    name: "aten_add_2"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_5"
    input: "model.decoder.layers.0.self_attn_layer_norm.weight"
    input: "model.decoder.layers.0.self_attn_layer_norm.bias"
    output: "model_decoder_layers_0_self_attn_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_self_attn_layer_norm_1_3"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_self_attn_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_0_self_attn_layer_norm_1"
    input: "model.decoder.layers.0.fc1.weight"
    input: "model.decoder.layers.0.fc1.bias"
    output: "model_decoder_layers_0_fc1_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1_4"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_0_fc1_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_0_fc1_1"
    output: "model_decoder_layers_0_activation_fn_1"
    name: "torch_nn_modules_activation_ReLU_model_decoder_layers_0_activation_fn_1_5"
    op_type: "torch_nn_modules_activation_ReLU_model_decoder_layers_0_activation_fn_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_0_activation_fn_1"
    output: "clone_7"
    name: "aten_clone_6"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_7"
    input: "model.decoder.layers.0.fc2.weight"
    input: "model.decoder.layers.0.fc2.bias"
    output: "model_decoder_layers_0_fc2_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1_7"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_0_fc2_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_0_fc2_1"
    output: "clone_8"
    name: "aten_clone_8"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model_decoder_layers_0_self_attn_layer_norm_1"
    input: "clone_8"
    output: "add_6"
    name: "aten_add_9"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_6"
    input: "model.decoder.layers.0.final_layer_norm.weight"
    input: "model.decoder.layers.0.final_layer_norm.bias"
    output: "model_decoder_layers_0_final_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_final_layer_norm_1_10"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_0_final_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  opset_import {
    domain: "pkg.transformers.4.34.0.dev0"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1"
  input: "getitem_3"
  input: "model.decoder.layers.1.self_attn.q_proj.weight"
  input: "model.decoder.layers.1.self_attn.q_proj.bias"
  output: "view_27"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_3"
    input: "_val_1"
    output: "view_26"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.q_proj.weight"
    output: "t_6"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.q_proj.bias"
    input: "view_26"
    input: "t_6"
    output: "addmm_6"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_6"
    input: "_val_7"
    output: "view_27"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1"
  input: "getitem_3"
  input: "model.decoder.layers.1.self_attn.k_proj.weight"
  input: "model.decoder.layers.1.self_attn.k_proj.bias"
  output: "view_29"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_3"
    input: "_val_1"
    output: "view_28"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.k_proj.weight"
    output: "t_7"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.k_proj.bias"
    input: "view_28"
    input: "t_7"
    output: "addmm_7"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_7"
    input: "_val_7"
    output: "view_29"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1"
  input: "getitem_3"
  input: "model.decoder.layers.1.self_attn.v_proj.weight"
  input: "model.decoder.layers.1.self_attn.v_proj.bias"
  output: "view_32"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_3"
    input: "_val_1"
    output: "view_31"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.v_proj.weight"
    output: "t_8"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.v_proj.bias"
    input: "view_31"
    input: "t_8"
    output: "addmm_8"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_8"
    input: "_val_7"
    output: "view_32"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1"
  input: "view_41"
  input: "model.decoder.layers.1.self_attn.out_proj.weight"
  input: "model.decoder.layers.1.self_attn.out_proj.bias"
  output: "view_43"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_41"
    input: "_val_1"
    output: "view_42"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.out_proj.weight"
    output: "t_9"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.self_attn.out_proj.bias"
    input: "view_42"
    input: "t_9"
    output: "addmm_9"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_9"
    input: "_val_7"
    output: "view_43"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1"
  input: "getitem_3"
  input: "expand_1"
  input: "model.decoder.layers.1.self_attn.q_proj.weight"
  input: "model.decoder.layers.1.self_attn.q_proj.bias"
  input: "model.decoder.layers.1.self_attn.k_proj.weight"
  input: "model.decoder.layers.1.self_attn.k_proj.bias"
  input: "model.decoder.layers.1.self_attn.v_proj.weight"
  input: "model.decoder.layers.1.self_attn.v_proj.bias"
  input: "model.decoder.layers.1.self_attn.out_proj.weight"
  input: "model.decoder.layers.1.self_attn.out_proj.bias"
  output: "clone_9"
  output: "clone_10"
  output: "model_decoder_layers_1_self_attn_out_proj_1"
  node {
    input: "getitem_3"
    input: "model.decoder.layers.1.self_attn.q_proj.weight"
    input: "model.decoder.layers.1.self_attn.q_proj.bias"
    output: "model_decoder_layers_1_self_attn_q_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1_11"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_q_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_5"
    name: "Constant_12"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\000>"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_1_self_attn_q_proj_1"
    input: "_val_5"
    output: "mul_3"
    name: "aten_mul_13"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_3"
    input: "model.decoder.layers.1.self_attn.k_proj.weight"
    input: "model.decoder.layers.1.self_attn.k_proj.bias"
    output: "model_decoder_layers_1_self_attn_k_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1_14"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_k_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_10"
    name: "Constant_15"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_1_self_attn_k_proj_1"
    input: "_val_10"
    output: "view_30"
    name: "aten_view_16"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_30"
    output: "transpose_5"
    name: "Transpose_17"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_5"
    output: "clone_9"
    name: "aten_clone_18"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_3"
    input: "model.decoder.layers.1.self_attn.v_proj.weight"
    input: "model.decoder.layers.1.self_attn.v_proj.bias"
    output: "model_decoder_layers_1_self_attn_v_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1_19"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_v_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_17"
    name: "Constant_20"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_1_self_attn_v_proj_1"
    input: "_val_17"
    output: "view_33"
    name: "aten_view_21"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_33"
    output: "transpose_6"
    name: "Transpose_22"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_6"
    output: "clone_10"
    name: "aten_clone_23"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_21"
    name: "Constant_24"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "mul_3"
    input: "_val_21"
    output: "view_34"
    name: "aten_view_25"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_34"
    output: "transpose_7"
    name: "Transpose_26"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_7"
    output: "clone_11"
    name: "aten_clone_27"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_25"
    name: "Constant_28"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_11"
    input: "_val_25"
    output: "view_35"
    name: "aten_view_29"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_27"
    name: "Constant_30"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_9"
    input: "_val_27"
    output: "view_36"
    name: "aten_view_31"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_29"
    name: "Constant_32"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_10"
    input: "_val_29"
    output: "view_37"
    name: "aten_view_33"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_36"
    output: "transpose_8"
    name: "Transpose_34"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      type: INTS
    }
  }
  node {
    input: "view_35"
    input: "transpose_8"
    output: "bmm_2"
    name: "aten_bmm_35"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_33"
    name: "Constant_36"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_2"
    input: "_val_33"
    output: "view_38"
    name: "aten_view_37"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_38"
    input: "expand_1"
    output: "add_7"
    name: "aten_add_38"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_36"
    name: "Constant_39"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "add_7"
    input: "_val_36"
    output: "view_39"
    name: "aten_view_40"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_39"
    output: "_softmax_1"
    name: "aten_softmax_no_dtype_41"
    op_type: "aten_softmax_no_dtype"
    attribute {
      name: "dim"
      i: -1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "_softmax_1"
    output: "clone_12"
    name: "aten_clone_42"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_12"
    input: "view_37"
    output: "bmm_3"
    name: "aten_bmm_43"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_41"
    name: "Constant_44"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_3"
    input: "_val_41"
    output: "view_40"
    name: "aten_view_45"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_40"
    output: "transpose_9"
    name: "Transpose_46"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_9"
    output: "clone_13"
    name: "aten_clone_47"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_45"
    name: "Constant_48"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_13"
    input: "_val_45"
    output: "view_41"
    name: "aten_view_49"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_41"
    input: "model.decoder.layers.1.self_attn.out_proj.weight"
    input: "model.decoder.layers.1.self_attn.out_proj.bias"
    output: "model_decoder_layers_1_self_attn_out_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1_50"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_1_self_attn_out_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_self_attn_layer_norm_1"
  input: "add_8"
  input: "model.decoder.layers.1.self_attn_layer_norm.weight"
  input: "model.decoder.layers.1.self_attn_layer_norm.bias"
  output: "native_layer_norm_2"
  node {
    input: "add_8"
    input: "model.decoder.layers.1.self_attn_layer_norm.weight"
    input: "model.decoder.layers.1.self_attn_layer_norm.bias"
    output: "native_layer_norm_2"
    output: "native_layer_norm_2_1"
    output: "native_layer_norm_2_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1"
  input: "getitem_6"
  input: "model.decoder.layers.1.fc1.weight"
  input: "model.decoder.layers.1.fc1.bias"
  output: "view_45"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_6"
    input: "_val_1"
    output: "view_44"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.fc1.weight"
    output: "t_10"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.fc1.bias"
    input: "view_44"
    input: "t_10"
    output: "addmm_10"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_10"
    input: "_val_7"
    output: "view_45"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_activation_ReLU_model_decoder_layers_1_activation_fn_1"
  input: "view_45"
  output: "relu_1"
  node {
    input: "view_45"
    output: "relu_1"
    name: "aten_relu_0"
    op_type: "aten_relu"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1"
  input: "clone_15"
  input: "model.decoder.layers.1.fc2.weight"
  input: "model.decoder.layers.1.fc2.bias"
  output: "view_47"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_15"
    input: "_val_1"
    output: "view_46"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.fc2.weight"
    output: "t_11"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.1.fc2.bias"
    input: "view_46"
    input: "t_11"
    output: "addmm_11"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_11"
    input: "_val_7"
    output: "view_47"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_final_layer_norm_1"
  input: "add_9"
  input: "model.decoder.layers.1.final_layer_norm.weight"
  input: "model.decoder.layers.1.final_layer_norm.bias"
  output: "native_layer_norm_3"
  node {
    input: "add_9"
    input: "model.decoder.layers.1.final_layer_norm.weight"
    input: "model.decoder.layers.1.final_layer_norm.bias"
    output: "native_layer_norm_3"
    output: "native_layer_norm_3_1"
    output: "native_layer_norm_3_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1"
  input: "getitem_3"
  input: "expand_1"
  input: "model.decoder.layers.1.self_attn.q_proj.weight"
  input: "model.decoder.layers.1.self_attn.q_proj.bias"
  input: "model.decoder.layers.1.self_attn.k_proj.weight"
  input: "model.decoder.layers.1.self_attn.k_proj.bias"
  input: "model.decoder.layers.1.self_attn.v_proj.weight"
  input: "model.decoder.layers.1.self_attn.v_proj.bias"
  input: "model.decoder.layers.1.self_attn.out_proj.weight"
  input: "model.decoder.layers.1.self_attn.out_proj.bias"
  input: "model.decoder.layers.1.self_attn_layer_norm.weight"
  input: "model.decoder.layers.1.self_attn_layer_norm.bias"
  input: "model.decoder.layers.1.fc1.weight"
  input: "model.decoder.layers.1.fc1.bias"
  input: "model.decoder.layers.1.fc2.weight"
  input: "model.decoder.layers.1.fc2.bias"
  input: "model.decoder.layers.1.final_layer_norm.weight"
  input: "model.decoder.layers.1.final_layer_norm.bias"
  output: "model_decoder_layers_1_self_attn_1"
  output: "model_decoder_layers_1_self_attn_1_1"
  output: "model_decoder_layers_1_final_layer_norm_1"
  node {
    input: "getitem_3"
    input: "expand_1"
    input: "model.decoder.layers.1.self_attn.q_proj.weight"
    input: "model.decoder.layers.1.self_attn.q_proj.bias"
    input: "model.decoder.layers.1.self_attn.k_proj.weight"
    input: "model.decoder.layers.1.self_attn.k_proj.bias"
    input: "model.decoder.layers.1.self_attn.v_proj.weight"
    input: "model.decoder.layers.1.self_attn.v_proj.bias"
    input: "model.decoder.layers.1.self_attn.out_proj.weight"
    input: "model.decoder.layers.1.self_attn.out_proj.bias"
    output: "model_decoder_layers_1_self_attn_1"
    output: "model_decoder_layers_1_self_attn_1_1"
    output: "model_decoder_layers_1_self_attn_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1_0"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_1_self_attn_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_1_self_attn_1_2"
    output: "clone_14"
    name: "aten_clone_1"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_3"
    input: "clone_14"
    output: "add_8"
    name: "aten_add_2"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_8"
    input: "model.decoder.layers.1.self_attn_layer_norm.weight"
    input: "model.decoder.layers.1.self_attn_layer_norm.bias"
    output: "model_decoder_layers_1_self_attn_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_self_attn_layer_norm_1_3"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_self_attn_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_1_self_attn_layer_norm_1"
    input: "model.decoder.layers.1.fc1.weight"
    input: "model.decoder.layers.1.fc1.bias"
    output: "model_decoder_layers_1_fc1_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1_4"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_1_fc1_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_1_fc1_1"
    output: "model_decoder_layers_1_activation_fn_1"
    name: "torch_nn_modules_activation_ReLU_model_decoder_layers_1_activation_fn_1_5"
    op_type: "torch_nn_modules_activation_ReLU_model_decoder_layers_1_activation_fn_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_1_activation_fn_1"
    output: "clone_15"
    name: "aten_clone_6"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_15"
    input: "model.decoder.layers.1.fc2.weight"
    input: "model.decoder.layers.1.fc2.bias"
    output: "model_decoder_layers_1_fc2_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1_7"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_1_fc2_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_1_fc2_1"
    output: "clone_16"
    name: "aten_clone_8"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model_decoder_layers_1_self_attn_layer_norm_1"
    input: "clone_16"
    output: "add_9"
    name: "aten_add_9"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_9"
    input: "model.decoder.layers.1.final_layer_norm.weight"
    input: "model.decoder.layers.1.final_layer_norm.bias"
    output: "model_decoder_layers_1_final_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_final_layer_norm_1_10"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_1_final_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  opset_import {
    domain: "pkg.transformers.4.34.0.dev0"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1"
  input: "getitem_9"
  input: "model.decoder.layers.2.self_attn.q_proj.weight"
  input: "model.decoder.layers.2.self_attn.q_proj.bias"
  output: "view_49"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_9"
    input: "_val_1"
    output: "view_48"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.q_proj.weight"
    output: "t_12"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.q_proj.bias"
    input: "view_48"
    input: "t_12"
    output: "addmm_12"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_12"
    input: "_val_7"
    output: "view_49"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1"
  input: "getitem_9"
  input: "model.decoder.layers.2.self_attn.k_proj.weight"
  input: "model.decoder.layers.2.self_attn.k_proj.bias"
  output: "view_51"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_9"
    input: "_val_1"
    output: "view_50"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.k_proj.weight"
    output: "t_13"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.k_proj.bias"
    input: "view_50"
    input: "t_13"
    output: "addmm_13"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_13"
    input: "_val_7"
    output: "view_51"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1"
  input: "getitem_9"
  input: "model.decoder.layers.2.self_attn.v_proj.weight"
  input: "model.decoder.layers.2.self_attn.v_proj.bias"
  output: "view_54"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_9"
    input: "_val_1"
    output: "view_53"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.v_proj.weight"
    output: "t_14"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.v_proj.bias"
    input: "view_53"
    input: "t_14"
    output: "addmm_14"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_14"
    input: "_val_7"
    output: "view_54"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1"
  input: "view_63"
  input: "model.decoder.layers.2.self_attn.out_proj.weight"
  input: "model.decoder.layers.2.self_attn.out_proj.bias"
  output: "view_65"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_63"
    input: "_val_1"
    output: "view_64"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.out_proj.weight"
    output: "t_15"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.self_attn.out_proj.bias"
    input: "view_64"
    input: "t_15"
    output: "addmm_15"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_15"
    input: "_val_7"
    output: "view_65"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1"
  input: "getitem_9"
  input: "expand_1"
  input: "model.decoder.layers.2.self_attn.q_proj.weight"
  input: "model.decoder.layers.2.self_attn.q_proj.bias"
  input: "model.decoder.layers.2.self_attn.k_proj.weight"
  input: "model.decoder.layers.2.self_attn.k_proj.bias"
  input: "model.decoder.layers.2.self_attn.v_proj.weight"
  input: "model.decoder.layers.2.self_attn.v_proj.bias"
  input: "model.decoder.layers.2.self_attn.out_proj.weight"
  input: "model.decoder.layers.2.self_attn.out_proj.bias"
  output: "clone_17"
  output: "clone_18"
  output: "model_decoder_layers_2_self_attn_out_proj_1"
  node {
    input: "getitem_9"
    input: "model.decoder.layers.2.self_attn.q_proj.weight"
    input: "model.decoder.layers.2.self_attn.q_proj.bias"
    output: "model_decoder_layers_2_self_attn_q_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1_11"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_q_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_5"
    name: "Constant_12"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\000>"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_2_self_attn_q_proj_1"
    input: "_val_5"
    output: "mul_4"
    name: "aten_mul_13"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_9"
    input: "model.decoder.layers.2.self_attn.k_proj.weight"
    input: "model.decoder.layers.2.self_attn.k_proj.bias"
    output: "model_decoder_layers_2_self_attn_k_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1_14"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_k_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_10"
    name: "Constant_15"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_2_self_attn_k_proj_1"
    input: "_val_10"
    output: "view_52"
    name: "aten_view_16"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_52"
    output: "transpose_10"
    name: "Transpose_17"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_10"
    output: "clone_17"
    name: "aten_clone_18"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_9"
    input: "model.decoder.layers.2.self_attn.v_proj.weight"
    input: "model.decoder.layers.2.self_attn.v_proj.bias"
    output: "model_decoder_layers_2_self_attn_v_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1_19"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_v_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_17"
    name: "Constant_20"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_2_self_attn_v_proj_1"
    input: "_val_17"
    output: "view_55"
    name: "aten_view_21"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_55"
    output: "transpose_11"
    name: "Transpose_22"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_11"
    output: "clone_18"
    name: "aten_clone_23"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_21"
    name: "Constant_24"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "mul_4"
    input: "_val_21"
    output: "view_56"
    name: "aten_view_25"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_56"
    output: "transpose_12"
    name: "Transpose_26"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_12"
    output: "clone_19"
    name: "aten_clone_27"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_25"
    name: "Constant_28"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_19"
    input: "_val_25"
    output: "view_57"
    name: "aten_view_29"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_27"
    name: "Constant_30"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_17"
    input: "_val_27"
    output: "view_58"
    name: "aten_view_31"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_29"
    name: "Constant_32"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_18"
    input: "_val_29"
    output: "view_59"
    name: "aten_view_33"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_58"
    output: "transpose_13"
    name: "Transpose_34"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      type: INTS
    }
  }
  node {
    input: "view_57"
    input: "transpose_13"
    output: "bmm_4"
    name: "aten_bmm_35"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_33"
    name: "Constant_36"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_4"
    input: "_val_33"
    output: "view_60"
    name: "aten_view_37"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_60"
    input: "expand_1"
    output: "add_10"
    name: "aten_add_38"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_36"
    name: "Constant_39"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "add_10"
    input: "_val_36"
    output: "view_61"
    name: "aten_view_40"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_61"
    output: "_softmax_2"
    name: "aten_softmax_no_dtype_41"
    op_type: "aten_softmax_no_dtype"
    attribute {
      name: "dim"
      i: -1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "_softmax_2"
    output: "clone_20"
    name: "aten_clone_42"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_20"
    input: "view_59"
    output: "bmm_5"
    name: "aten_bmm_43"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_41"
    name: "Constant_44"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_5"
    input: "_val_41"
    output: "view_62"
    name: "aten_view_45"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_62"
    output: "transpose_14"
    name: "Transpose_46"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_14"
    output: "clone_21"
    name: "aten_clone_47"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_45"
    name: "Constant_48"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_21"
    input: "_val_45"
    output: "view_63"
    name: "aten_view_49"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_63"
    input: "model.decoder.layers.2.self_attn.out_proj.weight"
    input: "model.decoder.layers.2.self_attn.out_proj.bias"
    output: "model_decoder_layers_2_self_attn_out_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1_50"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_2_self_attn_out_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_self_attn_layer_norm_1"
  input: "add_11"
  input: "model.decoder.layers.2.self_attn_layer_norm.weight"
  input: "model.decoder.layers.2.self_attn_layer_norm.bias"
  output: "native_layer_norm_4"
  node {
    input: "add_11"
    input: "model.decoder.layers.2.self_attn_layer_norm.weight"
    input: "model.decoder.layers.2.self_attn_layer_norm.bias"
    output: "native_layer_norm_4"
    output: "native_layer_norm_4_1"
    output: "native_layer_norm_4_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1"
  input: "getitem_12"
  input: "model.decoder.layers.2.fc1.weight"
  input: "model.decoder.layers.2.fc1.bias"
  output: "view_67"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_12"
    input: "_val_1"
    output: "view_66"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.fc1.weight"
    output: "t_16"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.fc1.bias"
    input: "view_66"
    input: "t_16"
    output: "addmm_16"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_16"
    input: "_val_7"
    output: "view_67"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_activation_ReLU_model_decoder_layers_2_activation_fn_1"
  input: "view_67"
  output: "relu_2"
  node {
    input: "view_67"
    output: "relu_2"
    name: "aten_relu_0"
    op_type: "aten_relu"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1"
  input: "clone_23"
  input: "model.decoder.layers.2.fc2.weight"
  input: "model.decoder.layers.2.fc2.bias"
  output: "view_69"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_23"
    input: "_val_1"
    output: "view_68"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.fc2.weight"
    output: "t_17"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.2.fc2.bias"
    input: "view_68"
    input: "t_17"
    output: "addmm_17"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_17"
    input: "_val_7"
    output: "view_69"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_final_layer_norm_1"
  input: "add_12"
  input: "model.decoder.layers.2.final_layer_norm.weight"
  input: "model.decoder.layers.2.final_layer_norm.bias"
  output: "native_layer_norm_5"
  node {
    input: "add_12"
    input: "model.decoder.layers.2.final_layer_norm.weight"
    input: "model.decoder.layers.2.final_layer_norm.bias"
    output: "native_layer_norm_5"
    output: "native_layer_norm_5_1"
    output: "native_layer_norm_5_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1"
  input: "getitem_9"
  input: "expand_1"
  input: "model.decoder.layers.2.self_attn.q_proj.weight"
  input: "model.decoder.layers.2.self_attn.q_proj.bias"
  input: "model.decoder.layers.2.self_attn.k_proj.weight"
  input: "model.decoder.layers.2.self_attn.k_proj.bias"
  input: "model.decoder.layers.2.self_attn.v_proj.weight"
  input: "model.decoder.layers.2.self_attn.v_proj.bias"
  input: "model.decoder.layers.2.self_attn.out_proj.weight"
  input: "model.decoder.layers.2.self_attn.out_proj.bias"
  input: "model.decoder.layers.2.self_attn_layer_norm.weight"
  input: "model.decoder.layers.2.self_attn_layer_norm.bias"
  input: "model.decoder.layers.2.fc1.weight"
  input: "model.decoder.layers.2.fc1.bias"
  input: "model.decoder.layers.2.fc2.weight"
  input: "model.decoder.layers.2.fc2.bias"
  input: "model.decoder.layers.2.final_layer_norm.weight"
  input: "model.decoder.layers.2.final_layer_norm.bias"
  output: "model_decoder_layers_2_self_attn_1"
  output: "model_decoder_layers_2_self_attn_1_1"
  output: "model_decoder_layers_2_final_layer_norm_1"
  node {
    input: "getitem_9"
    input: "expand_1"
    input: "model.decoder.layers.2.self_attn.q_proj.weight"
    input: "model.decoder.layers.2.self_attn.q_proj.bias"
    input: "model.decoder.layers.2.self_attn.k_proj.weight"
    input: "model.decoder.layers.2.self_attn.k_proj.bias"
    input: "model.decoder.layers.2.self_attn.v_proj.weight"
    input: "model.decoder.layers.2.self_attn.v_proj.bias"
    input: "model.decoder.layers.2.self_attn.out_proj.weight"
    input: "model.decoder.layers.2.self_attn.out_proj.bias"
    output: "model_decoder_layers_2_self_attn_1"
    output: "model_decoder_layers_2_self_attn_1_1"
    output: "model_decoder_layers_2_self_attn_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1_0"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_2_self_attn_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_2_self_attn_1_2"
    output: "clone_22"
    name: "aten_clone_1"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_9"
    input: "clone_22"
    output: "add_11"
    name: "aten_add_2"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_11"
    input: "model.decoder.layers.2.self_attn_layer_norm.weight"
    input: "model.decoder.layers.2.self_attn_layer_norm.bias"
    output: "model_decoder_layers_2_self_attn_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_self_attn_layer_norm_1_3"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_self_attn_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_2_self_attn_layer_norm_1"
    input: "model.decoder.layers.2.fc1.weight"
    input: "model.decoder.layers.2.fc1.bias"
    output: "model_decoder_layers_2_fc1_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1_4"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_2_fc1_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_2_fc1_1"
    output: "model_decoder_layers_2_activation_fn_1"
    name: "torch_nn_modules_activation_ReLU_model_decoder_layers_2_activation_fn_1_5"
    op_type: "torch_nn_modules_activation_ReLU_model_decoder_layers_2_activation_fn_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_2_activation_fn_1"
    output: "clone_23"
    name: "aten_clone_6"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_23"
    input: "model.decoder.layers.2.fc2.weight"
    input: "model.decoder.layers.2.fc2.bias"
    output: "model_decoder_layers_2_fc2_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1_7"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_2_fc2_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_2_fc2_1"
    output: "clone_24"
    name: "aten_clone_8"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model_decoder_layers_2_self_attn_layer_norm_1"
    input: "clone_24"
    output: "add_12"
    name: "aten_add_9"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_12"
    input: "model.decoder.layers.2.final_layer_norm.weight"
    input: "model.decoder.layers.2.final_layer_norm.bias"
    output: "model_decoder_layers_2_final_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_final_layer_norm_1_10"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_2_final_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  opset_import {
    domain: "pkg.transformers.4.34.0.dev0"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1"
  input: "getitem_15"
  input: "model.decoder.layers.3.self_attn.q_proj.weight"
  input: "model.decoder.layers.3.self_attn.q_proj.bias"
  output: "view_71"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_15"
    input: "_val_1"
    output: "view_70"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.q_proj.weight"
    output: "t_18"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.q_proj.bias"
    input: "view_70"
    input: "t_18"
    output: "addmm_18"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_18"
    input: "_val_7"
    output: "view_71"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1"
  input: "getitem_15"
  input: "model.decoder.layers.3.self_attn.k_proj.weight"
  input: "model.decoder.layers.3.self_attn.k_proj.bias"
  output: "view_73"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_15"
    input: "_val_1"
    output: "view_72"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.k_proj.weight"
    output: "t_19"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.k_proj.bias"
    input: "view_72"
    input: "t_19"
    output: "addmm_19"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_19"
    input: "_val_7"
    output: "view_73"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1"
  input: "getitem_15"
  input: "model.decoder.layers.3.self_attn.v_proj.weight"
  input: "model.decoder.layers.3.self_attn.v_proj.bias"
  output: "view_76"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_15"
    input: "_val_1"
    output: "view_75"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.v_proj.weight"
    output: "t_20"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.v_proj.bias"
    input: "view_75"
    input: "t_20"
    output: "addmm_20"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_20"
    input: "_val_7"
    output: "view_76"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1"
  input: "view_85"
  input: "model.decoder.layers.3.self_attn.out_proj.weight"
  input: "model.decoder.layers.3.self_attn.out_proj.bias"
  output: "view_87"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_85"
    input: "_val_1"
    output: "view_86"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.out_proj.weight"
    output: "t_21"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.self_attn.out_proj.bias"
    input: "view_86"
    input: "t_21"
    output: "addmm_21"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_21"
    input: "_val_7"
    output: "view_87"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1"
  input: "getitem_15"
  input: "expand_1"
  input: "model.decoder.layers.3.self_attn.q_proj.weight"
  input: "model.decoder.layers.3.self_attn.q_proj.bias"
  input: "model.decoder.layers.3.self_attn.k_proj.weight"
  input: "model.decoder.layers.3.self_attn.k_proj.bias"
  input: "model.decoder.layers.3.self_attn.v_proj.weight"
  input: "model.decoder.layers.3.self_attn.v_proj.bias"
  input: "model.decoder.layers.3.self_attn.out_proj.weight"
  input: "model.decoder.layers.3.self_attn.out_proj.bias"
  output: "clone_25"
  output: "clone_26"
  output: "model_decoder_layers_3_self_attn_out_proj_1"
  node {
    input: "getitem_15"
    input: "model.decoder.layers.3.self_attn.q_proj.weight"
    input: "model.decoder.layers.3.self_attn.q_proj.bias"
    output: "model_decoder_layers_3_self_attn_q_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1_11"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_q_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_5"
    name: "Constant_12"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\000>"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_3_self_attn_q_proj_1"
    input: "_val_5"
    output: "mul_5"
    name: "aten_mul_13"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_15"
    input: "model.decoder.layers.3.self_attn.k_proj.weight"
    input: "model.decoder.layers.3.self_attn.k_proj.bias"
    output: "model_decoder_layers_3_self_attn_k_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1_14"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_k_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_10"
    name: "Constant_15"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_3_self_attn_k_proj_1"
    input: "_val_10"
    output: "view_74"
    name: "aten_view_16"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_74"
    output: "transpose_15"
    name: "Transpose_17"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_15"
    output: "clone_25"
    name: "aten_clone_18"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_15"
    input: "model.decoder.layers.3.self_attn.v_proj.weight"
    input: "model.decoder.layers.3.self_attn.v_proj.bias"
    output: "model_decoder_layers_3_self_attn_v_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1_19"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_v_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_17"
    name: "Constant_20"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_3_self_attn_v_proj_1"
    input: "_val_17"
    output: "view_77"
    name: "aten_view_21"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_77"
    output: "transpose_16"
    name: "Transpose_22"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_16"
    output: "clone_26"
    name: "aten_clone_23"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_21"
    name: "Constant_24"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "mul_5"
    input: "_val_21"
    output: "view_78"
    name: "aten_view_25"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_78"
    output: "transpose_17"
    name: "Transpose_26"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_17"
    output: "clone_27"
    name: "aten_clone_27"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_25"
    name: "Constant_28"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_27"
    input: "_val_25"
    output: "view_79"
    name: "aten_view_29"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_27"
    name: "Constant_30"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_25"
    input: "_val_27"
    output: "view_80"
    name: "aten_view_31"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_29"
    name: "Constant_32"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_26"
    input: "_val_29"
    output: "view_81"
    name: "aten_view_33"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_80"
    output: "transpose_18"
    name: "Transpose_34"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      type: INTS
    }
  }
  node {
    input: "view_79"
    input: "transpose_18"
    output: "bmm_6"
    name: "aten_bmm_35"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_33"
    name: "Constant_36"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_6"
    input: "_val_33"
    output: "view_82"
    name: "aten_view_37"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_82"
    input: "expand_1"
    output: "add_13"
    name: "aten_add_38"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_36"
    name: "Constant_39"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "add_13"
    input: "_val_36"
    output: "view_83"
    name: "aten_view_40"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_83"
    output: "_softmax_3"
    name: "aten_softmax_no_dtype_41"
    op_type: "aten_softmax_no_dtype"
    attribute {
      name: "dim"
      i: -1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "_softmax_3"
    output: "clone_28"
    name: "aten_clone_42"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_28"
    input: "view_81"
    output: "bmm_7"
    name: "aten_bmm_43"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_41"
    name: "Constant_44"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_7"
    input: "_val_41"
    output: "view_84"
    name: "aten_view_45"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_84"
    output: "transpose_19"
    name: "Transpose_46"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_19"
    output: "clone_29"
    name: "aten_clone_47"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_45"
    name: "Constant_48"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_29"
    input: "_val_45"
    output: "view_85"
    name: "aten_view_49"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_85"
    input: "model.decoder.layers.3.self_attn.out_proj.weight"
    input: "model.decoder.layers.3.self_attn.out_proj.bias"
    output: "model_decoder_layers_3_self_attn_out_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1_50"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_3_self_attn_out_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_self_attn_layer_norm_1"
  input: "add_14"
  input: "model.decoder.layers.3.self_attn_layer_norm.weight"
  input: "model.decoder.layers.3.self_attn_layer_norm.bias"
  output: "native_layer_norm_6"
  node {
    input: "add_14"
    input: "model.decoder.layers.3.self_attn_layer_norm.weight"
    input: "model.decoder.layers.3.self_attn_layer_norm.bias"
    output: "native_layer_norm_6"
    output: "native_layer_norm_6_1"
    output: "native_layer_norm_6_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1"
  input: "getitem_18"
  input: "model.decoder.layers.3.fc1.weight"
  input: "model.decoder.layers.3.fc1.bias"
  output: "view_89"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_18"
    input: "_val_1"
    output: "view_88"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.fc1.weight"
    output: "t_22"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.fc1.bias"
    input: "view_88"
    input: "t_22"
    output: "addmm_22"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_22"
    input: "_val_7"
    output: "view_89"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_activation_ReLU_model_decoder_layers_3_activation_fn_1"
  input: "view_89"
  output: "relu_3"
  node {
    input: "view_89"
    output: "relu_3"
    name: "aten_relu_0"
    op_type: "aten_relu"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1"
  input: "clone_31"
  input: "model.decoder.layers.3.fc2.weight"
  input: "model.decoder.layers.3.fc2.bias"
  output: "view_91"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_31"
    input: "_val_1"
    output: "view_90"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.fc2.weight"
    output: "t_23"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.3.fc2.bias"
    input: "view_90"
    input: "t_23"
    output: "addmm_23"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_23"
    input: "_val_7"
    output: "view_91"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_final_layer_norm_1"
  input: "add_15"
  input: "model.decoder.layers.3.final_layer_norm.weight"
  input: "model.decoder.layers.3.final_layer_norm.bias"
  output: "native_layer_norm_7"
  node {
    input: "add_15"
    input: "model.decoder.layers.3.final_layer_norm.weight"
    input: "model.decoder.layers.3.final_layer_norm.bias"
    output: "native_layer_norm_7"
    output: "native_layer_norm_7_1"
    output: "native_layer_norm_7_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1"
  input: "getitem_15"
  input: "expand_1"
  input: "model.decoder.layers.3.self_attn.q_proj.weight"
  input: "model.decoder.layers.3.self_attn.q_proj.bias"
  input: "model.decoder.layers.3.self_attn.k_proj.weight"
  input: "model.decoder.layers.3.self_attn.k_proj.bias"
  input: "model.decoder.layers.3.self_attn.v_proj.weight"
  input: "model.decoder.layers.3.self_attn.v_proj.bias"
  input: "model.decoder.layers.3.self_attn.out_proj.weight"
  input: "model.decoder.layers.3.self_attn.out_proj.bias"
  input: "model.decoder.layers.3.self_attn_layer_norm.weight"
  input: "model.decoder.layers.3.self_attn_layer_norm.bias"
  input: "model.decoder.layers.3.fc1.weight"
  input: "model.decoder.layers.3.fc1.bias"
  input: "model.decoder.layers.3.fc2.weight"
  input: "model.decoder.layers.3.fc2.bias"
  input: "model.decoder.layers.3.final_layer_norm.weight"
  input: "model.decoder.layers.3.final_layer_norm.bias"
  output: "model_decoder_layers_3_self_attn_1"
  output: "model_decoder_layers_3_self_attn_1_1"
  output: "model_decoder_layers_3_final_layer_norm_1"
  node {
    input: "getitem_15"
    input: "expand_1"
    input: "model.decoder.layers.3.self_attn.q_proj.weight"
    input: "model.decoder.layers.3.self_attn.q_proj.bias"
    input: "model.decoder.layers.3.self_attn.k_proj.weight"
    input: "model.decoder.layers.3.self_attn.k_proj.bias"
    input: "model.decoder.layers.3.self_attn.v_proj.weight"
    input: "model.decoder.layers.3.self_attn.v_proj.bias"
    input: "model.decoder.layers.3.self_attn.out_proj.weight"
    input: "model.decoder.layers.3.self_attn.out_proj.bias"
    output: "model_decoder_layers_3_self_attn_1"
    output: "model_decoder_layers_3_self_attn_1_1"
    output: "model_decoder_layers_3_self_attn_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1_0"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_3_self_attn_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_3_self_attn_1_2"
    output: "clone_30"
    name: "aten_clone_1"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_15"
    input: "clone_30"
    output: "add_14"
    name: "aten_add_2"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_14"
    input: "model.decoder.layers.3.self_attn_layer_norm.weight"
    input: "model.decoder.layers.3.self_attn_layer_norm.bias"
    output: "model_decoder_layers_3_self_attn_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_self_attn_layer_norm_1_3"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_self_attn_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_3_self_attn_layer_norm_1"
    input: "model.decoder.layers.3.fc1.weight"
    input: "model.decoder.layers.3.fc1.bias"
    output: "model_decoder_layers_3_fc1_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1_4"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_3_fc1_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_3_fc1_1"
    output: "model_decoder_layers_3_activation_fn_1"
    name: "torch_nn_modules_activation_ReLU_model_decoder_layers_3_activation_fn_1_5"
    op_type: "torch_nn_modules_activation_ReLU_model_decoder_layers_3_activation_fn_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_3_activation_fn_1"
    output: "clone_31"
    name: "aten_clone_6"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_31"
    input: "model.decoder.layers.3.fc2.weight"
    input: "model.decoder.layers.3.fc2.bias"
    output: "model_decoder_layers_3_fc2_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1_7"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_3_fc2_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_3_fc2_1"
    output: "clone_32"
    name: "aten_clone_8"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model_decoder_layers_3_self_attn_layer_norm_1"
    input: "clone_32"
    output: "add_15"
    name: "aten_add_9"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_15"
    input: "model.decoder.layers.3.final_layer_norm.weight"
    input: "model.decoder.layers.3.final_layer_norm.bias"
    output: "model_decoder_layers_3_final_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_final_layer_norm_1_10"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_3_final_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  opset_import {
    domain: "pkg.transformers.4.34.0.dev0"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1"
  input: "getitem_21"
  input: "model.decoder.layers.4.self_attn.q_proj.weight"
  input: "model.decoder.layers.4.self_attn.q_proj.bias"
  output: "view_93"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_21"
    input: "_val_1"
    output: "view_92"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.q_proj.weight"
    output: "t_24"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.q_proj.bias"
    input: "view_92"
    input: "t_24"
    output: "addmm_24"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_24"
    input: "_val_7"
    output: "view_93"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1"
  input: "getitem_21"
  input: "model.decoder.layers.4.self_attn.k_proj.weight"
  input: "model.decoder.layers.4.self_attn.k_proj.bias"
  output: "view_95"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_21"
    input: "_val_1"
    output: "view_94"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.k_proj.weight"
    output: "t_25"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.k_proj.bias"
    input: "view_94"
    input: "t_25"
    output: "addmm_25"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_25"
    input: "_val_7"
    output: "view_95"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1"
  input: "getitem_21"
  input: "model.decoder.layers.4.self_attn.v_proj.weight"
  input: "model.decoder.layers.4.self_attn.v_proj.bias"
  output: "view_98"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_21"
    input: "_val_1"
    output: "view_97"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.v_proj.weight"
    output: "t_26"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.v_proj.bias"
    input: "view_97"
    input: "t_26"
    output: "addmm_26"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_26"
    input: "_val_7"
    output: "view_98"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1"
  input: "view_107"
  input: "model.decoder.layers.4.self_attn.out_proj.weight"
  input: "model.decoder.layers.4.self_attn.out_proj.bias"
  output: "view_109"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_107"
    input: "_val_1"
    output: "view_108"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.out_proj.weight"
    output: "t_27"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.self_attn.out_proj.bias"
    input: "view_108"
    input: "t_27"
    output: "addmm_27"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_27"
    input: "_val_7"
    output: "view_109"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1"
  input: "getitem_21"
  input: "expand_1"
  input: "model.decoder.layers.4.self_attn.q_proj.weight"
  input: "model.decoder.layers.4.self_attn.q_proj.bias"
  input: "model.decoder.layers.4.self_attn.k_proj.weight"
  input: "model.decoder.layers.4.self_attn.k_proj.bias"
  input: "model.decoder.layers.4.self_attn.v_proj.weight"
  input: "model.decoder.layers.4.self_attn.v_proj.bias"
  input: "model.decoder.layers.4.self_attn.out_proj.weight"
  input: "model.decoder.layers.4.self_attn.out_proj.bias"
  output: "clone_33"
  output: "clone_34"
  output: "model_decoder_layers_4_self_attn_out_proj_1"
  node {
    input: "getitem_21"
    input: "model.decoder.layers.4.self_attn.q_proj.weight"
    input: "model.decoder.layers.4.self_attn.q_proj.bias"
    output: "model_decoder_layers_4_self_attn_q_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1_11"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_q_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_5"
    name: "Constant_12"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\000>"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_4_self_attn_q_proj_1"
    input: "_val_5"
    output: "mul_6"
    name: "aten_mul_13"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_21"
    input: "model.decoder.layers.4.self_attn.k_proj.weight"
    input: "model.decoder.layers.4.self_attn.k_proj.bias"
    output: "model_decoder_layers_4_self_attn_k_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1_14"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_k_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_10"
    name: "Constant_15"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_4_self_attn_k_proj_1"
    input: "_val_10"
    output: "view_96"
    name: "aten_view_16"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_96"
    output: "transpose_20"
    name: "Transpose_17"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_20"
    output: "clone_33"
    name: "aten_clone_18"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_21"
    input: "model.decoder.layers.4.self_attn.v_proj.weight"
    input: "model.decoder.layers.4.self_attn.v_proj.bias"
    output: "model_decoder_layers_4_self_attn_v_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1_19"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_v_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_17"
    name: "Constant_20"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_4_self_attn_v_proj_1"
    input: "_val_17"
    output: "view_99"
    name: "aten_view_21"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_99"
    output: "transpose_21"
    name: "Transpose_22"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_21"
    output: "clone_34"
    name: "aten_clone_23"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_21"
    name: "Constant_24"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "mul_6"
    input: "_val_21"
    output: "view_100"
    name: "aten_view_25"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_100"
    output: "transpose_22"
    name: "Transpose_26"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_22"
    output: "clone_35"
    name: "aten_clone_27"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_25"
    name: "Constant_28"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_35"
    input: "_val_25"
    output: "view_101"
    name: "aten_view_29"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_27"
    name: "Constant_30"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_33"
    input: "_val_27"
    output: "view_102"
    name: "aten_view_31"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_29"
    name: "Constant_32"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_34"
    input: "_val_29"
    output: "view_103"
    name: "aten_view_33"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_102"
    output: "transpose_23"
    name: "Transpose_34"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      type: INTS
    }
  }
  node {
    input: "view_101"
    input: "transpose_23"
    output: "bmm_8"
    name: "aten_bmm_35"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_33"
    name: "Constant_36"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_8"
    input: "_val_33"
    output: "view_104"
    name: "aten_view_37"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_104"
    input: "expand_1"
    output: "add_16"
    name: "aten_add_38"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_36"
    name: "Constant_39"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "add_16"
    input: "_val_36"
    output: "view_105"
    name: "aten_view_40"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_105"
    output: "_softmax_4"
    name: "aten_softmax_no_dtype_41"
    op_type: "aten_softmax_no_dtype"
    attribute {
      name: "dim"
      i: -1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "_softmax_4"
    output: "clone_36"
    name: "aten_clone_42"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_36"
    input: "view_103"
    output: "bmm_9"
    name: "aten_bmm_43"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_41"
    name: "Constant_44"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_9"
    input: "_val_41"
    output: "view_106"
    name: "aten_view_45"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_106"
    output: "transpose_24"
    name: "Transpose_46"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_24"
    output: "clone_37"
    name: "aten_clone_47"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_45"
    name: "Constant_48"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_37"
    input: "_val_45"
    output: "view_107"
    name: "aten_view_49"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_107"
    input: "model.decoder.layers.4.self_attn.out_proj.weight"
    input: "model.decoder.layers.4.self_attn.out_proj.bias"
    output: "model_decoder_layers_4_self_attn_out_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1_50"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_4_self_attn_out_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_self_attn_layer_norm_1"
  input: "add_17"
  input: "model.decoder.layers.4.self_attn_layer_norm.weight"
  input: "model.decoder.layers.4.self_attn_layer_norm.bias"
  output: "native_layer_norm_8"
  node {
    input: "add_17"
    input: "model.decoder.layers.4.self_attn_layer_norm.weight"
    input: "model.decoder.layers.4.self_attn_layer_norm.bias"
    output: "native_layer_norm_8"
    output: "native_layer_norm_8_1"
    output: "native_layer_norm_8_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1"
  input: "getitem_24"
  input: "model.decoder.layers.4.fc1.weight"
  input: "model.decoder.layers.4.fc1.bias"
  output: "view_111"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_24"
    input: "_val_1"
    output: "view_110"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.fc1.weight"
    output: "t_28"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.fc1.bias"
    input: "view_110"
    input: "t_28"
    output: "addmm_28"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_28"
    input: "_val_7"
    output: "view_111"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_activation_ReLU_model_decoder_layers_4_activation_fn_1"
  input: "view_111"
  output: "relu_4"
  node {
    input: "view_111"
    output: "relu_4"
    name: "aten_relu_0"
    op_type: "aten_relu"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1"
  input: "clone_39"
  input: "model.decoder.layers.4.fc2.weight"
  input: "model.decoder.layers.4.fc2.bias"
  output: "view_113"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_39"
    input: "_val_1"
    output: "view_112"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.fc2.weight"
    output: "t_29"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.4.fc2.bias"
    input: "view_112"
    input: "t_29"
    output: "addmm_29"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_29"
    input: "_val_7"
    output: "view_113"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_final_layer_norm_1"
  input: "add_18"
  input: "model.decoder.layers.4.final_layer_norm.weight"
  input: "model.decoder.layers.4.final_layer_norm.bias"
  output: "native_layer_norm_9"
  node {
    input: "add_18"
    input: "model.decoder.layers.4.final_layer_norm.weight"
    input: "model.decoder.layers.4.final_layer_norm.bias"
    output: "native_layer_norm_9"
    output: "native_layer_norm_9_1"
    output: "native_layer_norm_9_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1"
  input: "getitem_21"
  input: "expand_1"
  input: "model.decoder.layers.4.self_attn.q_proj.weight"
  input: "model.decoder.layers.4.self_attn.q_proj.bias"
  input: "model.decoder.layers.4.self_attn.k_proj.weight"
  input: "model.decoder.layers.4.self_attn.k_proj.bias"
  input: "model.decoder.layers.4.self_attn.v_proj.weight"
  input: "model.decoder.layers.4.self_attn.v_proj.bias"
  input: "model.decoder.layers.4.self_attn.out_proj.weight"
  input: "model.decoder.layers.4.self_attn.out_proj.bias"
  input: "model.decoder.layers.4.self_attn_layer_norm.weight"
  input: "model.decoder.layers.4.self_attn_layer_norm.bias"
  input: "model.decoder.layers.4.fc1.weight"
  input: "model.decoder.layers.4.fc1.bias"
  input: "model.decoder.layers.4.fc2.weight"
  input: "model.decoder.layers.4.fc2.bias"
  input: "model.decoder.layers.4.final_layer_norm.weight"
  input: "model.decoder.layers.4.final_layer_norm.bias"
  output: "model_decoder_layers_4_self_attn_1"
  output: "model_decoder_layers_4_self_attn_1_1"
  output: "model_decoder_layers_4_final_layer_norm_1"
  node {
    input: "getitem_21"
    input: "expand_1"
    input: "model.decoder.layers.4.self_attn.q_proj.weight"
    input: "model.decoder.layers.4.self_attn.q_proj.bias"
    input: "model.decoder.layers.4.self_attn.k_proj.weight"
    input: "model.decoder.layers.4.self_attn.k_proj.bias"
    input: "model.decoder.layers.4.self_attn.v_proj.weight"
    input: "model.decoder.layers.4.self_attn.v_proj.bias"
    input: "model.decoder.layers.4.self_attn.out_proj.weight"
    input: "model.decoder.layers.4.self_attn.out_proj.bias"
    output: "model_decoder_layers_4_self_attn_1"
    output: "model_decoder_layers_4_self_attn_1_1"
    output: "model_decoder_layers_4_self_attn_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1_0"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_4_self_attn_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_4_self_attn_1_2"
    output: "clone_38"
    name: "aten_clone_1"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_21"
    input: "clone_38"
    output: "add_17"
    name: "aten_add_2"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_17"
    input: "model.decoder.layers.4.self_attn_layer_norm.weight"
    input: "model.decoder.layers.4.self_attn_layer_norm.bias"
    output: "model_decoder_layers_4_self_attn_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_self_attn_layer_norm_1_3"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_self_attn_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_4_self_attn_layer_norm_1"
    input: "model.decoder.layers.4.fc1.weight"
    input: "model.decoder.layers.4.fc1.bias"
    output: "model_decoder_layers_4_fc1_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1_4"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_4_fc1_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_4_fc1_1"
    output: "model_decoder_layers_4_activation_fn_1"
    name: "torch_nn_modules_activation_ReLU_model_decoder_layers_4_activation_fn_1_5"
    op_type: "torch_nn_modules_activation_ReLU_model_decoder_layers_4_activation_fn_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_4_activation_fn_1"
    output: "clone_39"
    name: "aten_clone_6"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_39"
    input: "model.decoder.layers.4.fc2.weight"
    input: "model.decoder.layers.4.fc2.bias"
    output: "model_decoder_layers_4_fc2_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1_7"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_4_fc2_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_4_fc2_1"
    output: "clone_40"
    name: "aten_clone_8"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model_decoder_layers_4_self_attn_layer_norm_1"
    input: "clone_40"
    output: "add_18"
    name: "aten_add_9"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_18"
    input: "model.decoder.layers.4.final_layer_norm.weight"
    input: "model.decoder.layers.4.final_layer_norm.bias"
    output: "model_decoder_layers_4_final_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_final_layer_norm_1_10"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_4_final_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  opset_import {
    domain: "pkg.transformers.4.34.0.dev0"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1"
  input: "getitem_27"
  input: "model.decoder.layers.5.self_attn.q_proj.weight"
  input: "model.decoder.layers.5.self_attn.q_proj.bias"
  output: "view_115"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_27"
    input: "_val_1"
    output: "view_114"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.q_proj.weight"
    output: "t_30"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.q_proj.bias"
    input: "view_114"
    input: "t_30"
    output: "addmm_30"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_30"
    input: "_val_7"
    output: "view_115"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1"
  input: "getitem_27"
  input: "model.decoder.layers.5.self_attn.k_proj.weight"
  input: "model.decoder.layers.5.self_attn.k_proj.bias"
  output: "view_117"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_27"
    input: "_val_1"
    output: "view_116"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.k_proj.weight"
    output: "t_31"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.k_proj.bias"
    input: "view_116"
    input: "t_31"
    output: "addmm_31"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_31"
    input: "_val_7"
    output: "view_117"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1"
  input: "getitem_27"
  input: "model.decoder.layers.5.self_attn.v_proj.weight"
  input: "model.decoder.layers.5.self_attn.v_proj.bias"
  output: "view_120"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_27"
    input: "_val_1"
    output: "view_119"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.v_proj.weight"
    output: "t_32"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.v_proj.bias"
    input: "view_119"
    input: "t_32"
    output: "addmm_32"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_32"
    input: "_val_7"
    output: "view_120"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1"
  input: "view_129"
  input: "model.decoder.layers.5.self_attn.out_proj.weight"
  input: "model.decoder.layers.5.self_attn.out_proj.bias"
  output: "view_131"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "view_129"
    input: "_val_1"
    output: "view_130"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.out_proj.weight"
    output: "t_33"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.self_attn.out_proj.bias"
    input: "view_130"
    input: "t_33"
    output: "addmm_33"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_33"
    input: "_val_7"
    output: "view_131"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1"
  input: "getitem_27"
  input: "expand_1"
  input: "model.decoder.layers.5.self_attn.q_proj.weight"
  input: "model.decoder.layers.5.self_attn.q_proj.bias"
  input: "model.decoder.layers.5.self_attn.k_proj.weight"
  input: "model.decoder.layers.5.self_attn.k_proj.bias"
  input: "model.decoder.layers.5.self_attn.v_proj.weight"
  input: "model.decoder.layers.5.self_attn.v_proj.bias"
  input: "model.decoder.layers.5.self_attn.out_proj.weight"
  input: "model.decoder.layers.5.self_attn.out_proj.bias"
  output: "clone_41"
  output: "clone_42"
  output: "model_decoder_layers_5_self_attn_out_proj_1"
  node {
    input: "getitem_27"
    input: "model.decoder.layers.5.self_attn.q_proj.weight"
    input: "model.decoder.layers.5.self_attn.q_proj.bias"
    output: "model_decoder_layers_5_self_attn_q_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1_11"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_q_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_5"
    name: "Constant_12"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\000>"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_5_self_attn_q_proj_1"
    input: "_val_5"
    output: "mul_7"
    name: "aten_mul_13"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_27"
    input: "model.decoder.layers.5.self_attn.k_proj.weight"
    input: "model.decoder.layers.5.self_attn.k_proj.bias"
    output: "model_decoder_layers_5_self_attn_k_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1_14"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_k_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_10"
    name: "Constant_15"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_5_self_attn_k_proj_1"
    input: "_val_10"
    output: "view_118"
    name: "aten_view_16"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_118"
    output: "transpose_25"
    name: "Transpose_17"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_25"
    output: "clone_41"
    name: "aten_clone_18"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_27"
    input: "model.decoder.layers.5.self_attn.v_proj.weight"
    input: "model.decoder.layers.5.self_attn.v_proj.bias"
    output: "model_decoder_layers_5_self_attn_v_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1_19"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_v_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_17"
    name: "Constant_20"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_layers_5_self_attn_v_proj_1"
    input: "_val_17"
    output: "view_121"
    name: "aten_view_21"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_121"
    output: "transpose_26"
    name: "Transpose_22"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_26"
    output: "clone_42"
    name: "aten_clone_23"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_21"
    name: "Constant_24"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "mul_7"
    input: "_val_21"
    output: "view_122"
    name: "aten_view_25"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_122"
    output: "transpose_27"
    name: "Transpose_26"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_27"
    output: "clone_43"
    name: "aten_clone_27"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_25"
    name: "Constant_28"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_43"
    input: "_val_25"
    output: "view_123"
    name: "aten_view_29"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_27"
    name: "Constant_30"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_41"
    input: "_val_27"
    output: "view_124"
    name: "aten_view_31"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_29"
    name: "Constant_32"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_42"
    input: "_val_29"
    output: "view_125"
    name: "aten_view_33"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_124"
    output: "transpose_28"
    name: "Transpose_34"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      type: INTS
    }
  }
  node {
    input: "view_123"
    input: "transpose_28"
    output: "bmm_10"
    name: "aten_bmm_35"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_33"
    name: "Constant_36"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_10"
    input: "_val_33"
    output: "view_126"
    name: "aten_view_37"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_126"
    input: "expand_1"
    output: "add_19"
    name: "aten_add_38"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_36"
    name: "Constant_39"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "add_19"
    input: "_val_36"
    output: "view_127"
    name: "aten_view_40"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_127"
    output: "_softmax_5"
    name: "aten_softmax_no_dtype_41"
    op_type: "aten_softmax_no_dtype"
    attribute {
      name: "dim"
      i: -1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "_softmax_5"
    output: "clone_44"
    name: "aten_clone_42"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_44"
    input: "view_125"
    output: "bmm_11"
    name: "aten_bmm_43"
    op_type: "aten_bmm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_41"
    name: "Constant_44"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 4
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000@\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "bmm_11"
    input: "_val_41"
    output: "view_128"
    name: "aten_view_45"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_128"
    output: "transpose_29"
    name: "Transpose_46"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 0
      ints: 2
      ints: 1
      ints: 3
      type: INTS
    }
  }
  node {
    input: "transpose_29"
    output: "clone_45"
    name: "aten_clone_47"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_45"
    name: "Constant_48"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_45"
    input: "_val_45"
    output: "view_129"
    name: "aten_view_49"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_129"
    input: "model.decoder.layers.5.self_attn.out_proj.weight"
    input: "model.decoder.layers.5.self_attn.out_proj.bias"
    output: "model_decoder_layers_5_self_attn_out_proj_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1_50"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_5_self_attn_out_proj_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_self_attn_layer_norm_1"
  input: "add_20"
  input: "model.decoder.layers.5.self_attn_layer_norm.weight"
  input: "model.decoder.layers.5.self_attn_layer_norm.bias"
  output: "native_layer_norm_10"
  node {
    input: "add_20"
    input: "model.decoder.layers.5.self_attn_layer_norm.weight"
    input: "model.decoder.layers.5.self_attn_layer_norm.bias"
    output: "native_layer_norm_10"
    output: "native_layer_norm_10_1"
    output: "native_layer_norm_10_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1"
  input: "getitem_30"
  input: "model.decoder.layers.5.fc1.weight"
  input: "model.decoder.layers.5.fc1.bias"
  output: "view_133"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_30"
    input: "_val_1"
    output: "view_132"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.fc1.weight"
    output: "t_34"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.fc1.bias"
    input: "view_132"
    input: "t_34"
    output: "addmm_34"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_34"
    input: "_val_7"
    output: "view_133"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_activation_ReLU_model_decoder_layers_5_activation_fn_1"
  input: "view_133"
  output: "relu_5"
  node {
    input: "view_133"
    output: "relu_5"
    name: "aten_relu_0"
    op_type: "aten_relu"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1"
  input: "clone_47"
  input: "model.decoder.layers.5.fc2.weight"
  input: "model.decoder.layers.5.fc2.bias"
  output: "view_135"
  node {
    output: "_val_1"
    name: "Constant_2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\010\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "clone_47"
    input: "_val_1"
    output: "view_134"
    name: "aten_view_3"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.fc2.weight"
    output: "t_35"
    name: "aten_t_4"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model.decoder.layers.5.fc2.bias"
    input: "view_134"
    input: "t_35"
    output: "addmm_35"
    name: "aten_addmm_5"
    op_type: "aten_addmm"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    attribute {
      name: "beta"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "addmm_35"
    input: "_val_7"
    output: "view_135"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_final_layer_norm_1"
  input: "add_21"
  input: "model.decoder.layers.5.final_layer_norm.weight"
  input: "model.decoder.layers.5.final_layer_norm.bias"
  output: "native_layer_norm_11"
  node {
    input: "add_21"
    input: "model.decoder.layers.5.final_layer_norm.weight"
    input: "model.decoder.layers.5.final_layer_norm.bias"
    output: "native_layer_norm_11"
    output: "native_layer_norm_11_1"
    output: "native_layer_norm_11_2"
    name: "LayerNormalization_0"
    op_type: "LayerNormalization"
    attribute {
      name: "axis"
      i: -1
      type: INT
    }
    attribute {
      name: "epsilon"
      f: 1e-05
      type: FLOAT
    }
    attribute {
      name: "stash_type"
      i: 1
      type: INT
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1"
  input: "getitem_27"
  input: "expand_1"
  input: "model.decoder.layers.5.self_attn.q_proj.weight"
  input: "model.decoder.layers.5.self_attn.q_proj.bias"
  input: "model.decoder.layers.5.self_attn.k_proj.weight"
  input: "model.decoder.layers.5.self_attn.k_proj.bias"
  input: "model.decoder.layers.5.self_attn.v_proj.weight"
  input: "model.decoder.layers.5.self_attn.v_proj.bias"
  input: "model.decoder.layers.5.self_attn.out_proj.weight"
  input: "model.decoder.layers.5.self_attn.out_proj.bias"
  input: "model.decoder.layers.5.self_attn_layer_norm.weight"
  input: "model.decoder.layers.5.self_attn_layer_norm.bias"
  input: "model.decoder.layers.5.fc1.weight"
  input: "model.decoder.layers.5.fc1.bias"
  input: "model.decoder.layers.5.fc2.weight"
  input: "model.decoder.layers.5.fc2.bias"
  input: "model.decoder.layers.5.final_layer_norm.weight"
  input: "model.decoder.layers.5.final_layer_norm.bias"
  output: "model_decoder_layers_5_self_attn_1"
  output: "model_decoder_layers_5_self_attn_1_1"
  output: "model_decoder_layers_5_final_layer_norm_1"
  node {
    input: "getitem_27"
    input: "expand_1"
    input: "model.decoder.layers.5.self_attn.q_proj.weight"
    input: "model.decoder.layers.5.self_attn.q_proj.bias"
    input: "model.decoder.layers.5.self_attn.k_proj.weight"
    input: "model.decoder.layers.5.self_attn.k_proj.bias"
    input: "model.decoder.layers.5.self_attn.v_proj.weight"
    input: "model.decoder.layers.5.self_attn.v_proj.bias"
    input: "model.decoder.layers.5.self_attn.out_proj.weight"
    input: "model.decoder.layers.5.self_attn.out_proj.bias"
    output: "model_decoder_layers_5_self_attn_1"
    output: "model_decoder_layers_5_self_attn_1_1"
    output: "model_decoder_layers_5_self_attn_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1_0"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Attention_model_decoder_layers_5_self_attn_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_5_self_attn_1_2"
    output: "clone_46"
    name: "aten_clone_1"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "getitem_27"
    input: "clone_46"
    output: "add_20"
    name: "aten_add_2"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_20"
    input: "model.decoder.layers.5.self_attn_layer_norm.weight"
    input: "model.decoder.layers.5.self_attn_layer_norm.bias"
    output: "model_decoder_layers_5_self_attn_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_self_attn_layer_norm_1_3"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_self_attn_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_5_self_attn_layer_norm_1"
    input: "model.decoder.layers.5.fc1.weight"
    input: "model.decoder.layers.5.fc1.bias"
    output: "model_decoder_layers_5_fc1_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1_4"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_5_fc1_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_5_fc1_1"
    output: "model_decoder_layers_5_activation_fn_1"
    name: "torch_nn_modules_activation_ReLU_model_decoder_layers_5_activation_fn_1_5"
    op_type: "torch_nn_modules_activation_ReLU_model_decoder_layers_5_activation_fn_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_5_activation_fn_1"
    output: "clone_47"
    name: "aten_clone_6"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone_47"
    input: "model.decoder.layers.5.fc2.weight"
    input: "model.decoder.layers.5.fc2.bias"
    output: "model_decoder_layers_5_fc2_1"
    name: "torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1_7"
    op_type: "torch_nn_modules_linear_Linear_model_decoder_layers_5_fc2_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    input: "model_decoder_layers_5_fc2_1"
    output: "clone_48"
    name: "aten_clone_8"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "model_decoder_layers_5_self_attn_layer_norm_1"
    input: "clone_48"
    output: "add_21"
    name: "aten_add_9"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_21"
    input: "model.decoder.layers.5.final_layer_norm.weight"
    input: "model.decoder.layers.5.final_layer_norm.bias"
    output: "model_decoder_layers_5_final_layer_norm_1"
    name: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_final_layer_norm_1_10"
    op_type: "torch_nn_modules_normalization_LayerNorm_model_decoder_layers_5_final_layer_norm_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  opset_import {
    domain: "pkg.transformers.4.34.0.dev0"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "aten_full"
  input: "size"
  input: "fill_value"
  output: "return_val"
  node {
    input: "size"
    output: "size_0"
    name: "n0"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 7
      type: INT
    }
  }
  node {
    input: "fill_value"
    output: "fill_value_1"
    name: "n1"
    op_type: "Cast"
    attribute {
      name: "to"
      type: INT
      ref_attr_name: "dtype"
    }
  }
  node {
    input: "fill_value_1"
    input: "size_0"
    output: "return_val"
    name: "n2"
    op_type: "Expand"
  }
  doc_string: "full(SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "dtype"
    i: 1
    type: INT
  }
}
functions {
  name: "aten_lt"
  input: "self"
  input: "other"
  output: "return_val"
  node {
    input: "self"
    input: "other"
    output: "return_val"
    name: "n0"
    op_type: "Less"
  }
  doc_string: "lt.Tensor(Tensor self, Tensor other) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_masked_fill"
  input: "self"
  input: "mask"
  input: "value"
  output: "return_val"
  node {
    input: "value"
    input: "self"
    output: "value_cast"
    name: "n0"
    op_type: "CastLike"
  }
  node {
    input: "mask"
    input: "value_cast"
    input: "self"
    output: "return_val"
    name: "n1"
    op_type: "Where"
  }
  doc_string: "masked_fill.Tensor(Tensor self, Tensor mask, Tensor value) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2Decoder_model_decoder_1"
  input: "l_input_ids_"
  input: "model.decoder.embed_tokens.weight"
  input: "model.decoder.embed_positions.weights"
  input: "model.decoder.layers.0.self_attn.q_proj.weight"
  input: "model.decoder.layers.0.self_attn.q_proj.bias"
  input: "model.decoder.layers.0.self_attn.k_proj.weight"
  input: "model.decoder.layers.0.self_attn.k_proj.bias"
  input: "model.decoder.layers.0.self_attn.v_proj.weight"
  input: "model.decoder.layers.0.self_attn.v_proj.bias"
  input: "model.decoder.layers.0.self_attn.out_proj.weight"
  input: "model.decoder.layers.0.self_attn.out_proj.bias"
  input: "model.decoder.layers.0.self_attn_layer_norm.weight"
  input: "model.decoder.layers.0.self_attn_layer_norm.bias"
  input: "model.decoder.layers.0.fc1.weight"
  input: "model.decoder.layers.0.fc1.bias"
  input: "model.decoder.layers.0.fc2.weight"
  input: "model.decoder.layers.0.fc2.bias"
  input: "model.decoder.layers.0.final_layer_norm.weight"
  input: "model.decoder.layers.0.final_layer_norm.bias"
  input: "model.decoder.layers.1.self_attn.q_proj.weight"
  input: "model.decoder.layers.1.self_attn.q_proj.bias"
  input: "model.decoder.layers.1.self_attn.k_proj.weight"
  input: "model.decoder.layers.1.self_attn.k_proj.bias"
  input: "model.decoder.layers.1.self_attn.v_proj.weight"
  input: "model.decoder.layers.1.self_attn.v_proj.bias"
  input: "model.decoder.layers.1.self_attn.out_proj.weight"
  input: "model.decoder.layers.1.self_attn.out_proj.bias"
  input: "model.decoder.layers.1.self_attn_layer_norm.weight"
  input: "model.decoder.layers.1.self_attn_layer_norm.bias"
  input: "model.decoder.layers.1.fc1.weight"
  input: "model.decoder.layers.1.fc1.bias"
  input: "model.decoder.layers.1.fc2.weight"
  input: "model.decoder.layers.1.fc2.bias"
  input: "model.decoder.layers.1.final_layer_norm.weight"
  input: "model.decoder.layers.1.final_layer_norm.bias"
  input: "model.decoder.layers.2.self_attn.q_proj.weight"
  input: "model.decoder.layers.2.self_attn.q_proj.bias"
  input: "model.decoder.layers.2.self_attn.k_proj.weight"
  input: "model.decoder.layers.2.self_attn.k_proj.bias"
  input: "model.decoder.layers.2.self_attn.v_proj.weight"
  input: "model.decoder.layers.2.self_attn.v_proj.bias"
  input: "model.decoder.layers.2.self_attn.out_proj.weight"
  input: "model.decoder.layers.2.self_attn.out_proj.bias"
  input: "model.decoder.layers.2.self_attn_layer_norm.weight"
  input: "model.decoder.layers.2.self_attn_layer_norm.bias"
  input: "model.decoder.layers.2.fc1.weight"
  input: "model.decoder.layers.2.fc1.bias"
  input: "model.decoder.layers.2.fc2.weight"
  input: "model.decoder.layers.2.fc2.bias"
  input: "model.decoder.layers.2.final_layer_norm.weight"
  input: "model.decoder.layers.2.final_layer_norm.bias"
  input: "model.decoder.layers.3.self_attn.q_proj.weight"
  input: "model.decoder.layers.3.self_attn.q_proj.bias"
  input: "model.decoder.layers.3.self_attn.k_proj.weight"
  input: "model.decoder.layers.3.self_attn.k_proj.bias"
  input: "model.decoder.layers.3.self_attn.v_proj.weight"
  input: "model.decoder.layers.3.self_attn.v_proj.bias"
  input: "model.decoder.layers.3.self_attn.out_proj.weight"
  input: "model.decoder.layers.3.self_attn.out_proj.bias"
  input: "model.decoder.layers.3.self_attn_layer_norm.weight"
  input: "model.decoder.layers.3.self_attn_layer_norm.bias"
  input: "model.decoder.layers.3.fc1.weight"
  input: "model.decoder.layers.3.fc1.bias"
  input: "model.decoder.layers.3.fc2.weight"
  input: "model.decoder.layers.3.fc2.bias"
  input: "model.decoder.layers.3.final_layer_norm.weight"
  input: "model.decoder.layers.3.final_layer_norm.bias"
  input: "model.decoder.layers.4.self_attn.q_proj.weight"
  input: "model.decoder.layers.4.self_attn.q_proj.bias"
  input: "model.decoder.layers.4.self_attn.k_proj.weight"
  input: "model.decoder.layers.4.self_attn.k_proj.bias"
  input: "model.decoder.layers.4.self_attn.v_proj.weight"
  input: "model.decoder.layers.4.self_attn.v_proj.bias"
  input: "model.decoder.layers.4.self_attn.out_proj.weight"
  input: "model.decoder.layers.4.self_attn.out_proj.bias"
  input: "model.decoder.layers.4.self_attn_layer_norm.weight"
  input: "model.decoder.layers.4.self_attn_layer_norm.bias"
  input: "model.decoder.layers.4.fc1.weight"
  input: "model.decoder.layers.4.fc1.bias"
  input: "model.decoder.layers.4.fc2.weight"
  input: "model.decoder.layers.4.fc2.bias"
  input: "model.decoder.layers.4.final_layer_norm.weight"
  input: "model.decoder.layers.4.final_layer_norm.bias"
  input: "model.decoder.layers.5.self_attn.q_proj.weight"
  input: "model.decoder.layers.5.self_attn.q_proj.bias"
  input: "model.decoder.layers.5.self_attn.k_proj.weight"
  input: "model.decoder.layers.5.self_attn.k_proj.bias"
  input: "model.decoder.layers.5.self_attn.v_proj.weight"
  input: "model.decoder.layers.5.self_attn.v_proj.bias"
  input: "model.decoder.layers.5.self_attn.out_proj.weight"
  input: "model.decoder.layers.5.self_attn.out_proj.bias"
  input: "model.decoder.layers.5.self_attn_layer_norm.weight"
  input: "model.decoder.layers.5.self_attn_layer_norm.bias"
  input: "model.decoder.layers.5.fc1.weight"
  input: "model.decoder.layers.5.fc1.bias"
  input: "model.decoder.layers.5.fc2.weight"
  input: "model.decoder.layers.5.fc2.bias"
  input: "model.decoder.layers.5.final_layer_norm.weight"
  input: "model.decoder.layers.5.final_layer_norm.bias"
  output: "model_decoder_layers_0_1"
  output: "model_decoder_layers_0_1_1"
  output: "model_decoder_layers_1_1"
  output: "model_decoder_layers_1_1_1"
  output: "model_decoder_layers_2_1"
  output: "model_decoder_layers_2_1_1"
  output: "model_decoder_layers_3_1"
  output: "model_decoder_layers_3_1_1"
  output: "model_decoder_layers_4_1"
  output: "model_decoder_layers_4_1_1"
  output: "model_decoder_layers_5_1"
  output: "model_decoder_layers_5_1_1"
  output: "model_decoder_layers_5_1_2"
  node {
    output: "_val_1"
    name: "Constant_12"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\377\377\377\377\377\377\377\377\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "l_input_ids_"
    input: "_val_1"
    output: "view"
    name: "aten_view_13"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view"
    input: "model.decoder.embed_tokens.weight"
    output: "model_decoder_embed_tokens_1"
    name: "torch_nn_modules_sparse_Embedding_model_decoder_embed_tokens_1_14"
    op_type: "torch_nn_modules_sparse_Embedding_model_decoder_embed_tokens_1"
    domain: "pkg.torch.2.2.0a0+git63d65dd"
  }
  node {
    output: "_val_5"
    name: "Constant_15"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\200A"
      }
      type: TENSOR
    }
  }
  node {
    input: "model_decoder_embed_tokens_1"
    input: "_val_5"
    output: "mul"
    name: "aten_mul_16"
    op_type: "aten_mul"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_7"
    name: "Constant_17"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    output: "_val_8"
    name: "Constant_18"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\377\377\177\377"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_7"
    input: "_val_8"
    output: "full"
    name: "aten_full_19"
    op_type: "aten_full"
    attribute {
      name: "dtype"
      i: 1
      type: INT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_10"
    name: "Constant_20"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    output: "_val_11"
    name: "Constant_21"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_10"
    input: "_val_11"
    output: "_val_12"
    name: "CastLike_22"
    op_type: "CastLike"
  }
  node {
    output: "_val_13"
    name: "Constant_23"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 1
        raw_data: "\000\000\200?"
      }
      type: TENSOR
    }
  }
  node {
    output: "_val_14"
    name: "Constant_24"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_13"
    input: "_val_14"
    output: "_val_15"
    name: "CastLike_25"
    op_type: "CastLike"
  }
  node {
    output: "_val_16"
    name: "Constant_26"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "_val_12"
    input: "_val_16"
    input: "_val_15"
    output: "arange"
    name: "Range_27"
    op_type: "Range"
  }
  node {
    output: "_val_18"
    name: "Constant_28"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "arange"
    input: "_val_18"
    output: "add"
    name: "aten_add_29"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_20"
    name: "Constant_30"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "add"
    input: "_val_20"
    output: "view_1"
    name: "aten_view_31"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "arange"
    input: "view_1"
    output: "lt"
    name: "aten_lt_32"
    op_type: "aten_lt"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_23"
    name: "Constant_33"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        raw_data: "\000\000\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "full"
    input: "lt"
    input: "_val_23"
    output: "masked_fill"
    name: "aten_masked_fill_34"
    op_type: "aten_masked_fill"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view"
    input: "model.decoder.embed_positions.weights"
    output: "model_decoder_embed_positions_1"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1_35"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2SinusoidalPositionalEmbedding_model_decoder_embed_positions_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "mul"
    input: "model_decoder_embed_positions_1"
    output: "add_3"
    name: "aten_add_36"
    op_type: "aten_add"
    attribute {
      name: "alpha"
      f: 1.0
      type: FLOAT
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "add_3"
    output: "clone"
    name: "aten_clone_37"
    op_type: "aten_clone"
    attribute {
      name: "memory_format"
      s: ""
      type: STRING
    }
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "clone"
    input: "masked_fill"
    input: "model.decoder.layers.0.self_attn.q_proj.weight"
    input: "model.decoder.layers.0.self_attn.q_proj.bias"
    input: "model.decoder.layers.0.self_attn.k_proj.weight"
    input: "model.decoder.layers.0.self_attn.k_proj.bias"
    input: "model.decoder.layers.0.self_attn.v_proj.weight"
    input: "model.decoder.layers.0.self_attn.v_proj.bias"
    input: "model.decoder.layers.0.self_attn.out_proj.weight"
    input: "model.decoder.layers.0.self_attn.out_proj.bias"
    input: "model.decoder.layers.0.self_attn_layer_norm.weight"
    input: "model.decoder.layers.0.self_attn_layer_norm.bias"
    input: "model.decoder.layers.0.fc1.weight"
    input: "model.decoder.layers.0.fc1.bias"
    input: "model.decoder.layers.0.fc2.weight"
    input: "model.decoder.layers.0.fc2.bias"
    input: "model.decoder.layers.0.final_layer_norm.weight"
    input: "model.decoder.layers.0.final_layer_norm.bias"
    output: "model_decoder_layers_0_1"
    output: "model_decoder_layers_0_1_1"
    output: "model_decoder_layers_0_1_2"
    output: "model_decoder_layers_0_1_3"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1_38"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_0_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_0_1_3"
    input: "model_decoder_layers_0_1_2"
    input: "model.decoder.layers.1.self_attn.q_proj.weight"
    input: "model.decoder.layers.1.self_attn.q_proj.bias"
    input: "model.decoder.layers.1.self_attn.k_proj.weight"
    input: "model.decoder.layers.1.self_attn.k_proj.bias"
    input: "model.decoder.layers.1.self_attn.v_proj.weight"
    input: "model.decoder.layers.1.self_attn.v_proj.bias"
    input: "model.decoder.layers.1.self_attn.out_proj.weight"
    input: "model.decoder.layers.1.self_attn.out_proj.bias"
    input: "model.decoder.layers.1.self_attn_layer_norm.weight"
    input: "model.decoder.layers.1.self_attn_layer_norm.bias"
    input: "model.decoder.layers.1.fc1.weight"
    input: "model.decoder.layers.1.fc1.bias"
    input: "model.decoder.layers.1.fc2.weight"
    input: "model.decoder.layers.1.fc2.bias"
    input: "model.decoder.layers.1.final_layer_norm.weight"
    input: "model.decoder.layers.1.final_layer_norm.bias"
    output: "model_decoder_layers_1_1"
    output: "model_decoder_layers_1_1_1"
    output: "model_decoder_layers_1_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1_39"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_1_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_1_1_2"
    input: "model_decoder_layers_0_1_2"
    input: "model.decoder.layers.2.self_attn.q_proj.weight"
    input: "model.decoder.layers.2.self_attn.q_proj.bias"
    input: "model.decoder.layers.2.self_attn.k_proj.weight"
    input: "model.decoder.layers.2.self_attn.k_proj.bias"
    input: "model.decoder.layers.2.self_attn.v_proj.weight"
    input: "model.decoder.layers.2.self_attn.v_proj.bias"
    input: "model.decoder.layers.2.self_attn.out_proj.weight"
    input: "model.decoder.layers.2.self_attn.out_proj.bias"
    input: "model.decoder.layers.2.self_attn_layer_norm.weight"
    input: "model.decoder.layers.2.self_attn_layer_norm.bias"
    input: "model.decoder.layers.2.fc1.weight"
    input: "model.decoder.layers.2.fc1.bias"
    input: "model.decoder.layers.2.fc2.weight"
    input: "model.decoder.layers.2.fc2.bias"
    input: "model.decoder.layers.2.final_layer_norm.weight"
    input: "model.decoder.layers.2.final_layer_norm.bias"
    output: "model_decoder_layers_2_1"
    output: "model_decoder_layers_2_1_1"
    output: "model_decoder_layers_2_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1_40"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_2_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_2_1_2"
    input: "model_decoder_layers_0_1_2"
    input: "model.decoder.layers.3.self_attn.q_proj.weight"
    input: "model.decoder.layers.3.self_attn.q_proj.bias"
    input: "model.decoder.layers.3.self_attn.k_proj.weight"
    input: "model.decoder.layers.3.self_attn.k_proj.bias"
    input: "model.decoder.layers.3.self_attn.v_proj.weight"
    input: "model.decoder.layers.3.self_attn.v_proj.bias"
    input: "model.decoder.layers.3.self_attn.out_proj.weight"
    input: "model.decoder.layers.3.self_attn.out_proj.bias"
    input: "model.decoder.layers.3.self_attn_layer_norm.weight"
    input: "model.decoder.layers.3.self_attn_layer_norm.bias"
    input: "model.decoder.layers.3.fc1.weight"
    input: "model.decoder.layers.3.fc1.bias"
    input: "model.decoder.layers.3.fc2.weight"
    input: "model.decoder.layers.3.fc2.bias"
    input: "model.decoder.layers.3.final_layer_norm.weight"
    input: "model.decoder.layers.3.final_layer_norm.bias"
    output: "model_decoder_layers_3_1"
    output: "model_decoder_layers_3_1_1"
    output: "model_decoder_layers_3_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1_41"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_3_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_3_1_2"
    input: "model_decoder_layers_0_1_2"
    input: "model.decoder.layers.4.self_attn.q_proj.weight"
    input: "model.decoder.layers.4.self_attn.q_proj.bias"
    input: "model.decoder.layers.4.self_attn.k_proj.weight"
    input: "model.decoder.layers.4.self_attn.k_proj.bias"
    input: "model.decoder.layers.4.self_attn.v_proj.weight"
    input: "model.decoder.layers.4.self_attn.v_proj.bias"
    input: "model.decoder.layers.4.self_attn.out_proj.weight"
    input: "model.decoder.layers.4.self_attn.out_proj.bias"
    input: "model.decoder.layers.4.self_attn_layer_norm.weight"
    input: "model.decoder.layers.4.self_attn_layer_norm.bias"
    input: "model.decoder.layers.4.fc1.weight"
    input: "model.decoder.layers.4.fc1.bias"
    input: "model.decoder.layers.4.fc2.weight"
    input: "model.decoder.layers.4.fc2.bias"
    input: "model.decoder.layers.4.final_layer_norm.weight"
    input: "model.decoder.layers.4.final_layer_norm.bias"
    output: "model_decoder_layers_4_1"
    output: "model_decoder_layers_4_1_1"
    output: "model_decoder_layers_4_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1_42"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_4_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  node {
    input: "model_decoder_layers_4_1_2"
    input: "model_decoder_layers_0_1_2"
    input: "model.decoder.layers.5.self_attn.q_proj.weight"
    input: "model.decoder.layers.5.self_attn.q_proj.bias"
    input: "model.decoder.layers.5.self_attn.k_proj.weight"
    input: "model.decoder.layers.5.self_attn.k_proj.bias"
    input: "model.decoder.layers.5.self_attn.v_proj.weight"
    input: "model.decoder.layers.5.self_attn.v_proj.bias"
    input: "model.decoder.layers.5.self_attn.out_proj.weight"
    input: "model.decoder.layers.5.self_attn.out_proj.bias"
    input: "model.decoder.layers.5.self_attn_layer_norm.weight"
    input: "model.decoder.layers.5.self_attn_layer_norm.bias"
    input: "model.decoder.layers.5.fc1.weight"
    input: "model.decoder.layers.5.fc1.bias"
    input: "model.decoder.layers.5.fc2.weight"
    input: "model.decoder.layers.5.fc2.bias"
    input: "model.decoder.layers.5.final_layer_norm.weight"
    input: "model.decoder.layers.5.final_layer_norm.bias"
    output: "model_decoder_layers_5_1"
    output: "model_decoder_layers_5_1_1"
    output: "model_decoder_layers_5_1_2"
    name: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1_43"
    op_type: "transformers_models_speech_to_text_2_modeling_speech_to_text_2_Speech2Text2DecoderLayer_model_decoder_layers_5_1"
    domain: "pkg.transformers.4.34.0.dev0"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  opset_import {
    domain: "pkg.torch.2.2.0a0+git63d65dd"
    version: 1
  }
  opset_import {
    domain: "pkg.transformers.4.34.0.dev0"
    version: 1
  }
  domain: "pkg.transformers.4.34.0.dev0"
}
functions {
  name: "aten_mm"
  input: "self"
  input: "mat2"
  output: "return_val"
  node {
    input: "self"
    input: "mat2"
    output: "return_val"
    name: "n0"
    op_type: "MatMul"
  }
  doc_string: "mm(Tensor self, Tensor mat2) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "torch_nn_modules_linear_Linear_lm_head_1"
  input: "getitem_33"
  input: "model.decoder.embed_tokens.weight"
  output: "view_137"
  node {
    input: "model.decoder.embed_tokens.weight"
    output: "t_36"
    name: "aten_t_2"
    op_type: "aten_t"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_3"
    name: "Constant_3"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 2
        data_type: 7
        raw_data: "\200\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "getitem_33"
    input: "_val_3"
    output: "view_136"
    name: "aten_view_4"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    input: "view_136"
    input: "t_36"
    output: "mm"
    name: "aten_mm_5"
    op_type: "aten_mm"
    domain: "pkg.onnxscript.torch_lib"
  }
  node {
    output: "_val_6"
    name: "Constant_6"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        dims: 3
        data_type: 7
        raw_data: "\001\000\000\000\000\000\000\000\200\000\000\000\000\000\000\000\020\'\000\000\000\000\000\000"
      }
      type: TENSOR
    }
  }
  node {
    input: "mm"
    input: "_val_6"
    output: "view_137"
    name: "aten_view_7"
    op_type: "aten_view"
    domain: "pkg.onnxscript.torch_lib"
  }
  opset_import {
    domain: ""
    version: 18
  }
  opset_import {
    domain: "pkg.onnxscript.torch_lib"
    version: 1
  }
  domain: "pkg.torch.2.2.0a0+git63d65dd"
}
functions {
  name: "aten__log_softmax"
  input: "self"
  output: "result_7"
  attribute: "dim"
  attribute: "half_to_float"
  node {
    input: "self"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_0"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 0
        name: "int64_0"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_0"
    input: "tmp_0"
    output: "int64_0_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "tmp_0"
    input: "int64_0_cast"
    output: "self_is_scalar"
    name: "n4"
    op_type: "Equal"
  }
  node {
    input: "self_is_scalar"
    output: "self_4"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          output: "tmp_1"
          name: "n0"
          op_type: "Constant"
          attribute {
            name: "value_ints"
            ints: 0
            type: INTS
          }
        }
        node {
          input: "self"
          input: "tmp_1"
          output: "self_2"
          name: "n1"
          op_type: "Unsqueeze"
        }
        name: "thenGraph_8"
        output {
          name: "self_2"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          output: "self_3"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_8"
        output {
          name: "self_3"
        }
      }
      type: GRAPH
    }
  }
  node {
    input: "self_4"
    output: "result"
    name: "n6"
    op_type: "LogSoftmax"
    attribute {
      name: "axis"
      type: INT
      ref_attr_name: "dim"
    }
  }
  node {
    input: "self_is_scalar"
    output: "result_7"
    name: "n7"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "result"
          output: "result_5"
          name: "n0"
          op_type: "Squeeze"
        }
        name: "thenGraph_11"
        output {
          name: "result_5"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "result"
          output: "result_6"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_11"
        output {
          name: "result_6"
        }
      }
      type: GRAPH
    }
  }
  doc_string: "_log_softmax(Tensor self, int dim, bool half_to_float) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_where"
  input: "condition"
  input: "self"
  input: "other"
  output: "return_val"
  node {
    input: "condition"
    input: "self"
    input: "other"
    output: "return_val"
    name: "n0"
    op_type: "Where"
  }
  doc_string: "where.self(Tensor condition, Tensor self, Tensor other) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_gather"
  input: "self"
  input: "index"
  output: "result_16"
  attribute: "dim"
  node {
    input: "index"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_0"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 0
        name: "int64_0"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_0"
    input: "tmp_0"
    output: "int64_0_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "tmp_0"
    input: "int64_0_cast"
    output: "cond"
    name: "n4"
    op_type: "Equal"
  }
  node {
    input: "cond"
    output: "result_16"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "self"
          output: "result"
          name: "n0"
          op_type: "Identity"
        }
        name: "thenGraph_10"
        output {
          name: "result"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          output: "tmp_1"
          name: "n0"
          op_type: "Shape"
        }
        node {
          input: "tmp_1"
          output: "tmp_2"
          name: "n1"
          op_type: "Size"
        }
        node {
          output: "int64_0_3"
          name: "n2"
          op_type: "Constant"
          attribute {
            name: "value"
            t {
              data_type: 7
              int64_data: 0
              name: "int64_0_3"
            }
            type: TENSOR
          }
        }
        node {
          input: "int64_0_3"
          input: "tmp_2"
          output: "int64_0_3_cast"
          name: "n3"
          op_type: "CastLike"
        }
        node {
          input: "tmp_2"
          input: "int64_0_3_cast"
          output: "cond_4"
          name: "n4"
          op_type: "Equal"
        }
        node {
          input: "cond_4"
          output: "self_8"
          name: "n5"
          op_type: "If"
          attribute {
            name: "then_branch"
            g {
              node {
                output: "tmp_5"
                name: "n0"
                op_type: "Constant"
                attribute {
                  name: "value_ints"
                  ints: -1
                  type: INTS
                }
              }
              node {
                input: "self"
                input: "tmp_5"
                output: "self_6"
                name: "n1"
                op_type: "Reshape"
              }
              name: "thenGraph_13"
              output {
                name: "self_6"
              }
            }
            type: GRAPH
          }
          attribute {
            name: "else_branch"
            g {
              node {
                input: "self"
                output: "self_7"
                name: "n0"
                op_type: "Identity"
              }
              name: "elseGraph_13"
              output {
                name: "self_7"
              }
            }
            type: GRAPH
          }
        }
        node {
          input: "index"
          output: "tmp_9"
          name: "n6"
          op_type: "Size"
        }
        node {
          output: "int64_0_10"
          name: "n7"
          op_type: "Constant"
          attribute {
            name: "value"
            t {
              data_type: 7
              int64_data: 0
              name: "int64_0_10"
            }
            type: TENSOR
          }
        }
        node {
          input: "int64_0_10"
          input: "tmp_9"
          output: "int64_0_10_cast"
          name: "n8"
          op_type: "CastLike"
        }
        node {
          input: "tmp_9"
          input: "int64_0_10_cast"
          output: "cond_11"
          name: "n9"
          op_type: "Equal"
        }
        node {
          input: "cond_11"
          output: "result_15"
          name: "n10"
          op_type: "If"
          attribute {
            name: "then_branch"
            g {
              node {
                input: "index"
                input: "self_8"
                output: "result_12"
                name: "n0"
                op_type: "CastLike"
              }
              name: "thenGraph_15"
              output {
                name: "result_12"
              }
            }
            type: GRAPH
          }
          attribute {
            name: "else_branch"
            g {
              node {
                input: "index"
                output: "index_13"
                name: "n0"
                op_type: "Cast"
                attribute {
                  name: "to"
                  i: 7
                  type: INT
                }
              }
              node {
                input: "self_8"
                input: "index_13"
                output: "result_14"
                name: "n1"
                op_type: "GatherElements"
                attribute {
                  name: "axis"
                  type: INT
                  ref_attr_name: "dim"
                }
              }
              name: "elseGraph_15"
              output {
                name: "result_14"
              }
            }
            type: GRAPH
          }
        }
        name: "elseGraph_10"
        output {
          name: "result_15"
        }
      }
      type: GRAPH
    }
  }
  doc_string: "gather(Tensor self, int dim, Tensor index, *, bool sparse_grad=False) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "sparse_grad"
    i: 0
    type: INT
  }
}
functions {
  name: "aten_squeeze_dim"
  input: "self"
  output: "result_7"
  attribute: "dim"
  node {
    input: "self"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_0"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 0
        name: "int64_0"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_0"
    input: "tmp_0"
    output: "int64_0_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "tmp_0"
    input: "int64_0_cast"
    output: "cond"
    name: "n4"
    op_type: "Greater"
  }
  node {
    input: "cond"
    output: "result_7"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "self"
          output: "shape"
          name: "n0"
          op_type: "Shape"
        }
        node {
          output: "dim"
          name: "n1"
          op_type: "Constant"
          attribute {
            name: "value_int"
            type: INT
            ref_attr_name: "dim"
          }
        }
        node {
          input: "shape"
          input: "dim"
          output: "dim_size"
          name: "n2"
          op_type: "Gather"
          attribute {
            name: "axis"
            i: 0
            type: INT
          }
        }
        node {
          output: "int64_1"
          name: "n3"
          op_type: "Constant"
          attribute {
            name: "value"
            t {
              data_type: 7
              int64_data: 1
              name: "int64_1"
            }
            type: TENSOR
          }
        }
        node {
          input: "int64_1"
          input: "dim_size"
          output: "int64_1_cast"
          name: "n4"
          op_type: "CastLike"
        }
        node {
          input: "dim_size"
          input: "int64_1_cast"
          output: "cond_1"
          name: "n5"
          op_type: "Equal"
        }
        node {
          input: "cond_1"
          output: "result_5"
          name: "n6"
          op_type: "If"
          attribute {
            name: "then_branch"
            g {
              node {
                output: "dim_2"
                name: "n0"
                op_type: "Constant"
                attribute {
                  name: "value_int"
                  type: INT
                  ref_attr_name: "dim"
                }
              }
              node {
                output: "tmp_3"
                name: "n1"
                op_type: "Constant"
                attribute {
                  name: "value_ints"
                  ints: -1
                  type: INTS
                }
              }
              node {
                input: "dim_2"
                input: "tmp_3"
                output: "dims"
                name: "n2"
                op_type: "Reshape"
              }
              node {
                input: "self"
                input: "dims"
                output: "result"
                name: "n3"
                op_type: "Squeeze"
              }
              name: "thenGraph_8"
              output {
                name: "result"
              }
            }
            type: GRAPH
          }
          attribute {
            name: "else_branch"
            g {
              node {
                input: "self"
                output: "result_4"
                name: "n0"
                op_type: "Identity"
              }
              name: "elseGraph_8"
              output {
                name: "result_4"
              }
            }
            type: GRAPH
          }
        }
        name: "thenGraph_4"
        output {
          name: "result_5"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          output: "result_6"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_4"
        output {
          name: "result_6"
        }
      }
      type: GRAPH
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "aten_neg"
  input: "self"
  output: "return_val"
  node {
    input: "self"
    output: "return_val"
    name: "n0"
    op_type: "Neg"
  }
  doc_string: "neg(Tensor self) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "_aten_sum_dim_none"
  input: "self"
  output: "result_7"
  node {
    input: "self"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "int64_0"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value"
      t {
        data_type: 7
        int64_data: 0
        name: "int64_0"
      }
      type: TENSOR
    }
  }
  node {
    input: "int64_0"
    input: "tmp_0"
    output: "int64_0_cast"
    name: "n3"
    op_type: "CastLike"
  }
  node {
    input: "tmp_0"
    input: "int64_0_cast"
    output: "self_is_scalar"
    name: "n4"
    op_type: "Equal"
  }
  node {
    input: "self_is_scalar"
    output: "self_4"
    name: "n5"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          output: "tmp_1"
          name: "n0"
          op_type: "Constant"
          attribute {
            name: "value_ints"
            ints: -1
            type: INTS
          }
        }
        node {
          input: "self"
          input: "tmp_1"
          output: "self_2"
          name: "n1"
          op_type: "Reshape"
        }
        name: "thenGraph_4"
        output {
          name: "self_2"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "self"
          output: "self_3"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_4"
        output {
          name: "self_3"
        }
      }
      type: GRAPH
    }
  }
  node {
    input: "self_4"
    output: "result"
    name: "n6"
    op_type: "ReduceSum"
    attribute {
      name: "keepdims"
      type: INT
      ref_attr_name: "keepdim"
    }
  }
  node {
    input: "self_is_scalar"
    output: "result_7"
    name: "n7"
    op_type: "If"
    attribute {
      name: "then_branch"
      g {
        node {
          input: "result"
          output: "result_5"
          name: "n0"
          op_type: "Squeeze"
        }
        name: "thenGraph_9"
        output {
          name: "result_5"
        }
      }
      type: GRAPH
    }
    attribute {
      name: "else_branch"
      g {
        node {
          input: "result"
          output: "result_6"
          name: "n0"
          op_type: "Identity"
        }
        name: "elseGraph_9"
        output {
          name: "result_6"
        }
      }
      type: GRAPH
    }
  }
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
  attribute_proto {
    name: "keepdim"
    i: 0
    type: INT
  }
}
functions {
  name: "aten_div"
  input: "self"
  input: "other"
  output: "return_val"
  node {
    input: "self"
    input: "other"
    output: "return_val"
    name: "n0"
    op_type: "Div"
  }
  doc_string: "div.Tensor(Tensor self, Tensor other) -> Tensor"
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib"
}
functions {
  name: "Rank"
  input: "input"
  output: "return_val"
  node {
    input: "input"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "return_val"
    name: "n1"
    op_type: "Size"
  }
  doc_string: "Take the rank of the input tensor."
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib.common"
}
functions {
  name: "IsScalar"
  input: "input"
  output: "return_val"
  node {
    input: "input"
    output: "tmp"
    name: "n0"
    op_type: "Shape"
  }
  node {
    input: "tmp"
    output: "tmp_0"
    name: "n1"
    op_type: "Size"
  }
  node {
    output: "tmp_1"
    name: "n2"
    op_type: "Constant"
    attribute {
      name: "value_int"
      i: 0
      type: INT
    }
  }
  node {
    input: "tmp_0"
    input: "tmp_1"
    output: "return_val"
    name: "n3"
    op_type: "Equal"
  }
  doc_string: "Return whether the input has rank 0, or is a scalar."
  opset_import {
    domain: ""
    version: 18
  }
  domain: "pkg.onnxscript.torch_lib.common"
}
